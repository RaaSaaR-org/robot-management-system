{
  "master": {
    "tasks": [
      {
        "id": "1",
        "title": "Setup Core Infrastructure (Foundation Phase)",
        "description": "Establish the foundational shared infrastructure including UI components, common hooks, API client, and state management store.",
        "details": "Implement the following modules as defined in Phase 0:\n- **shared/components/ui**: Implement primitive UI elements like `Button`, `Card`, `Input`, `Modal`, `Badge` with Tailwind CSS for styling.\n- **shared/hooks**: Create base hooks such as `useApi`, `useDebounce`, `useWebSocket`, `useLocalStorage`.\n- **api/client**: Set up an Axios instance with interceptors for handling authentication tokens, errors, and retries.\n- **store/createStore**: Implement a Zustand factory with middleware for devtools and persistence, ensuring it produces typed stores.",
        "testStrategy": "Utilize Vitest for unit tests on all implemented components and hooks. Mock API calls using MSW for `api/client` tests to ensure correct token handling and error responses. Verify that the Zustand store factory produces typed stores and integrates with devtools/persistence as expected.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": "2",
        "title": "Implement User Authentication & Authorization",
        "description": "Develop the full authentication flow including user login, token management, and role-based access control (RBAC).",
        "details": "Implement the following modules as defined in Phase 1:\n- **auth/store**: Create an authentication Zustand store to manage token state.\n- **auth/api**: Implement API calls for login, logout, and token refresh endpoints.\n- **auth/hooks**: Develop `useAuth()` hook for authentication state management.\n- **UI Components**: Create `LoginForm`, `LogoutButton` components using `shared/ui` primitives.\n- **ProtectedRoute**: Implement a component to guard routes based on authentication status.\n- **AuthProvider**: Establish a React context provider for authentication state.\n- **LoginPage**: Develop the login page that utilizes the `LoginForm` and `useAuth()` hook.",
        "testStrategy": "Perform unit tests for `auth/store`, `auth/api` (with mocked API), and `auth/hooks`. Use React Testing Library for `LoginForm`, `LogoutButton`, and `ProtectedRoute` components. Test critical scenarios including happy path (valid credentials, successful login, token stored), edge cases (empty fields, malformed email), and error cases (invalid credentials, network failure) as per PRD's critical test scenarios.",
        "priority": "high",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": "3",
        "title": "Develop Core Robot Management Features",
        "description": "Implement essential CRUD operations and status display for individual robot entities within the platform.",
        "details": "Implement the following modules as defined in Phase 2:\n- **robots/types**: Define TypeScript types for `Robot`, `RobotStatus`, `RobotTelemetry`, `RobotCommand`, `CommandInterpretation`, etc.\n- **robots/store**: Create a Zustand store for robot data, supporting CRUD operations and filtering.\n- **robots/api**: Implement API calls for listing, getting, and sending commands to robots.\n- **robots/hooks**: Develop `useRobotList()` and `useRobot()` hooks for data fetching and state management.\n- **UI Components**: Create `RobotStatusBadge` (color-coded status), `RobotCard`, `RobotList` (paginated grid/list), and `RobotDetailPanel` (comprehensive single robot view) using `shared/ui` primitives.\n- **Pages**: Develop `RobotsPage` for listing and `RobotDetailPage` for individual robot details.",
        "testStrategy": "Conduct unit tests for `robots/types`, `robots/store`, `robots/api` (with mocked API), and `robots/hooks`. Use React Testing Library for UI components such as `RobotStatusBadge`, `RobotCard`, `RobotList`, and `RobotDetailPanel`. Critical test scenarios include fetching and displaying robot list (happy path), handling empty lists, and API failures, ensuring real-time status updates are reflected.",
        "priority": "high",
        "dependencies": [
          "1",
          "2"
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": "4",
        "title": "Implement Task Lifecycle Management",
        "description": "Enable viewing, tracking, and basic management (cancel/pause) of tasks assigned to robots.",
        "details": "Implement the following modules as defined in Phase 3:\n- **tasks/types**: Define TypeScript types for `Task`, `TaskStatus`, `TaskStep`, etc., dependent on `robots/types`.\n- **tasks/store**: Create a Zustand store for task data.\n- **tasks/api**: Implement API calls for listing tasks, getting task details, and actions like cancelling or pausing tasks.\n- **tasks/hooks**: Develop `useTask()` and `useTaskQueue()` hooks.\n- **UI Components**: Create `TaskCard`, `TaskList` (with filtering), and `TaskTimeline` (step-by-step progress) components using `shared/ui` primitives.\n- **Pages**: Develop `TasksPage` to display the task list and provide detailed views.",
        "testStrategy": "Perform unit tests for `tasks/types`, `tasks/store`, `tasks/api` (mocked), and `tasks/hooks`. Use React Testing Library for UI components (`TaskCard`, `TaskList`, `TaskTimeline`) to verify correct data display and state transitions. Ensure that task status updates and actions like cancel/pause are correctly handled and reflected in the UI.",
        "priority": "medium",
        "dependencies": [
          "1",
          "3"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2025-12-14T00:08:11.439Z"
      },
      {
        "id": "5",
        "title": "Develop Real-time Telemetry & Monitoring",
        "description": "Integrate WebSocket-based real-time telemetry to display battery levels and sensor data for robots.",
        "details": "Implement the following features as part of Phase 4:\n- **telemetry/hooks**: Implement `useTelemetryStream()` using the `shared/hooks/useWebSocket` to connect to real-time telemetry feeds and consume data dependent on `robots/types`.\n- **UI Components**: Create a `BatteryGauge` component to visually represent battery levels with warnings, and a `SensorGrid` component to display key sensor readings in a readable format. These components should use `shared/ui` primitives and connect to the `useTelemetryStream()` hook. Ensure updates occur at 5-10 second intervals.",
        "testStrategy": "Unit test `useTelemetryStream()` hook with mocked WebSocket connections, simulating various telemetry data streams and disconnections. Use React Testing Library for `BatteryGauge` and `SensorGrid` components to verify correct visual representation and real-time updates based on incoming data. Test warning thresholds for battery levels.",
        "priority": "medium",
        "dependencies": [
          "1",
          "3"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2025-12-14T00:15:11.601Z"
      },
      {
        "id": "6",
        "title": "Implement Safety & Alert System",
        "description": "Integrate critical safety features including an emergency stop button and a comprehensive alert notification system.",
        "details": "Implement the following modules/features as part of Phase 4:\n- **alerts/types**: Define TypeScript types for `Alert`, `AlertSeverity`, dependent on `robots/types`.\n- **alerts/store**: Create a Zustand store for alert management.\n- **alerts/hooks**: Develop `useAlerts()` hook for alert management.\n- **UI Components**: Create `AlertBanner` (for critical/warning/info events), `AlertList` (displaying all active alerts), and an `EmergencyStopButton` (always-visible, sending immediate stop command via `robots/api`) using `shared/ui` primitives. Ensure alerts are displayed by severity and require acknowledgment for critical events.",
        "testStrategy": "Unit test `alerts/types`, `alerts/store`, `alerts/hooks`. Use React Testing Library for `AlertBanner`, `AlertList`, and `EmergencyStopButton`. Critical test scenarios for E-stop include tapping to immediately send a stop command, requiring confirmation to resume, and handling offline states by queuing commands. Test alert display based on severity, acknowledgment functionality, and integration with `robots/api` for the E-stop.",
        "priority": "high",
        "dependencies": [
          "1",
          "3",
          "5"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2025-12-14T00:31:38.387Z"
      },
      {
        "id": "7",
        "title": "Build Natural Language Command Interface",
        "description": "Develop the user interface for inputting and interpreting natural language commands for robots.",
        "details": "Implement the following modules/features as part of Phase 5:\n- **command/api**: Implement API calls for `sendCommand()` including VLA interpretation, dependent on `api/client` and `robots/types`.\n- **command/hooks**: Develop `useCommand()` hook, dependent on `command/api` and `robots/hooks`.\n- **UI Components**: Create a `CommandBar` for natural language text input, `CommandPreview` to display the VLA model's interpretation (action type, objects, confidence), `CommandConfirmation` modal for user confirmation before execution, and `CommandHistory` to log and search past commands. These components should use `shared/ui` primitives.",
        "testStrategy": "Unit test `command/api` (mocked API) and `command/hooks`. Use React Testing Library for `CommandBar`, `CommandPreview`, `CommandConfirmation`, and `CommandHistory`. Critical test scenarios include entering a command, displaying its interpretation, confirming execution, and logging history. Test edge cases like low confidence interpretations, ambiguous commands, VLA timeout, and blocked/prohibited actions with appropriate user feedback.",
        "priority": "high",
        "dependencies": [
          "1",
          "3",
          "5"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2025-12-14T01:00:59.810Z"
      },
      {
        "id": "8",
        "title": "Implement Safety Simulation Preview",
        "description": "Integrate a 2D/3D preview functionality for planned robot actions to enhance safety and user confidence.",
        "details": "Implement the `Safety Simulation Preview` feature as an advanced part of the Command Interface (Phase 5):\n- Integrate `Three.js` (chosen for its lighter weight and community support) for rendering the 2D/3D preview.\n- Utilize planned action data from `command/hooks` and current robot position/environment data (potentially from `telemetry/components` and `robots/hooks`) to generate an animated preview of the robot's path and actions.\n- The preview should highlight potential hazards and show grip points for manipulation tasks.\n- Start with a 2D path preview and iterate towards 3D simulation, as per risk mitigation strategies.",
        "testStrategy": "Conduct integration tests to ensure the simulation preview accurately reflects the planned action based on command interpretation. Visually inspect the 2D/3D animations for correctness. Test hazard highlighting and grip point visualization. Test with various command types and environmental conditions. Validate that the preview updates dynamically with changes in planned actions.",
        "priority": "medium",
        "dependencies": [
          "1",
          "5",
          "7"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2025-12-14T01:25:17.077Z"
      },
      {
        "id": "9",
        "title": "Develop Fleet Overview Dashboard & Map",
        "description": "Create a high-level fleet monitoring dashboard and an interactive map to visualize robot positions and aggregate statuses.",
        "details": "Implement the following modules/features as defined in Phase 6:\n- **fleet/hooks**: Develop `useFleetStatus()` hook, dependent on `robots/hooks` and `alerts/hooks`, to aggregate fleet-wide data.\n- **UI Components**: Create `FleetStats` for displaying KPI cards (robot counts by status, alert count, utilization metrics) using `shared/ui` primitives.\n- **FleetMap**: Implement an interactive 2D map using `Leaflet.js` to render floor plans and plot robot markers. Support zoom/pan and cluster markers for large fleets.\n- **ZoneOverlay**: Develop a component to display operational zones or exclusion areas on the `FleetMap`.\n- **FleetDashboard page**: Assemble `FleetStats`, `FleetMap`, `CommandBar` (from Task 7), and `AlertBanner` (from Task 6) into a comprehensive dashboard view.",
        "testStrategy": "Unit test `fleet/hooks` for correct data aggregation. Use React Testing Library for `FleetStats` components. For `FleetMap` and `ZoneOverlay`, perform integration tests to verify correct rendering of floor plans, accurate plotting of robot positions, marker clustering, and interactive features (zoom/pan). Ensure `FleetDashboard` correctly displays aggregated data and integrates other components.",
        "priority": "medium",
        "dependencies": [
          "1",
          "3",
          "6"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2025-12-14T02:02:29.577Z"
      },
      {
        "id": "10",
        "title": "Enhance Cross-Platform UI & Application Polish",
        "description": "Implement responsive layouts, dark mode support, offline capabilities, and finalize application routing for a production-ready experience.",
        "details": "Implement the following features as defined in Phase 7:\n- **Responsive Layouts**: Apply adaptive layouts for mobile, tablet, and desktop viewing across all pages, using breakpoints to adjust column counts (1/2/3).\n- **Navigation Components**: Create `MobileNav` and `Sidebar` components.\n- **Theme Switching**: Implement `ThemeProvider` with dark mode support (system-preference-aware with user override) using `shared/utils`.\n- **Offline Support**: Implement an offline indicator and caching mechanism using `shared/hooks/useOffline` and the global `store` to cache robot states and queue commands for syncing on reconnect.\n- **Layouts**: Create `DashboardLayout`, `AuthLayout`, and `MobileLayout` that incorporate navigation and core components.\n- **App Routing**: Finalize `app/Router` with lazy loading for all feature pages and integrating the new layouts.",
        "testStrategy": "Perform extensive end-to-end (E2E) testing with Playwright to verify responsive layouts across different viewport sizes. Test dark mode functionality, ensuring correct theme application based on system preference and user override. Validate offline support by simulating network disconnections: verify offline indicator, cached data display, and command queuing/syncing on reconnect. Test all routing and lazy loading works as expected. Accessibility testing with `axe-core` should be integrated for all UI components and pages.",
        "priority": "medium",
        "dependencies": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2025-12-14T02:29:12.553Z"
      },
      {
        "id": "11",
        "title": "Authentication & User Management (Full Stack)",
        "description": "Implement complete authentication system with user registration, password management, and account settings across frontend and server.",
        "details": "**Full-Stack Feature spanning Frontend + Server**\n\n## Frontend (`app/src/features/auth/`)\n- **Registration UI**: Create `RegistrationForm`, `RegisterPage` using types from `auth.types.ts` (`RegisterRequest`)\n- **Password Reset UI**: Create `ForgotPasswordForm`, `ResetPasswordForm`, `ForgotPasswordPage`, `ResetPasswordPage`\n- **Account Settings**: Create `AccountSettingsPanel`, `ChangePasswordForm`, `AccountPage`\n- **auth/api**: Wire registration endpoint `POST /auth/register`, password reset endpoints\n- **auth/store**: Add registration, password reset, account settings actions to `authStore.ts`\n- **auth/hooks**: Add `useRegistration()`, `usePasswordReset()`, `useAccountSettings()` hooks\n\n## Server (`server/src/`)\n- **Auth routes**: `POST /auth/register`, `POST /auth/forgot-password`, `POST /auth/reset-password`, `POST /auth/change-password`\n- **AuthService**: User CRUD, password hashing with bcrypt, JWT token generation\n- **Auth middleware**: JWT validation on protected routes\n- **Database**: User model with Prisma schema\n\n**Key Files:**\n- Frontend: `app/src/features/auth/types/auth.types.ts`, `app/src/features/auth/api/authApi.ts`, `app/src/features/auth/store/authStore.ts`\n- Server: Create `server/src/routes/auth.routes.ts`, `server/src/services/AuthService.ts`, `server/src/middleware/auth.middleware.ts`\n- Server: Update `server/prisma/schema.prisma` with User model",
        "testStrategy": "Frontend: Unit test auth store actions, React Testing Library for form components, E2E test registration/password reset flows. Server: Supertest for auth endpoints, test password hashing, test JWT validation, test token refresh flow.",
        "priority": "high",
        "dependencies": [
          "1",
          "2"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2025-12-22T22:11:16.478Z"
      },
      {
        "id": "12",
        "title": "Alerts System (Full Stack)",
        "description": "Implement comprehensive alerts system with history, acknowledgment, and real-time push across frontend, server, and robot client.",
        "details": "**Full-Stack Feature spanning Frontend + Server + Robot**\n\n## Frontend (`app/src/features/alerts/`)\n- **Alert History**: Create `AlertHistoryPanel`, `AlertsPage` with pagination\n- **Filters**: Create `AlertFilters` component (by severity, source, date range)\n- **Acknowledgment UI**: Add acknowledge button/action to alert components\n- **alerts/api**: Create `alertsApi.ts` with CRUD endpoints, wire to server\n- **alerts/store**: Update `alertsStore.ts` to fetch from API, add pagination state\n- **alerts/hooks**: Update `useAlerts()` to fetch from API, add `useAlertHistory()` hook\n\n## Server (`server/src/`)\n- **Alert routes**: `GET /api/alerts`, `POST /api/alerts`, `POST /api/alerts/:id/acknowledge`, `GET /api/alerts/history`\n- **AlertService**: Alert management, severity handling, acknowledgment logic\n- **WebSocket**: Push new alerts via existing WebSocket to connected clients\n- **Database**: Alert model with severity, source, acknowledged status\n\n## Robot Client (`robot-agent/src/`)\n- **Alert emission**: Enhance `robot/telemetry.ts` to emit alert events (errors, warnings, battery low)\n- **State tracking**: Update `robot/state.ts` to track alert conditions\n- **A2A events**: Send alert events to server via existing A2A protocol\n\n**Key Files:**\n- Frontend: `app/src/features/alerts/store/alertsStore.ts`, create `app/src/features/alerts/api/alertsApi.ts`\n- Server: Create `server/src/routes/alert.routes.ts`, `server/src/services/AlertService.ts`\n- Robot: `robot-agent/src/robot/telemetry.ts`, `robot-agent/src/robot/state.ts`",
        "testStrategy": "Frontend: Test API fetches alerts, test acknowledgment UI, test history pagination. Server: Test alert CRUD, test WebSocket push, test filtering. Robot: Test alert emission on error conditions, test battery low alerts.",
        "priority": "high",
        "dependencies": [
          "1",
          "6"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2025-12-22T22:42:32.474Z"
      },
      {
        "id": "13",
        "title": "Zone Management (Full Stack)",
        "description": "Implement zone management for fleet operations with zone editor, validation, and robot zone awareness.",
        "details": "**Full-Stack Feature spanning Frontend + Server + Robot**\n\n## Frontend (`app/src/features/fleet/`)\n- **Zone Editor**: Add zone drawing/editing mode to `FleetMap.tsx`\n- **Zone CRUD UI**: Create `ZoneEditor`, `ZoneConfigPanel`, `ZoneFormModal` components\n- **Zone Display**: Enhance `ZoneOverlay` to show zones with different colors by type\n- **fleet/api**: Create `fleetApi.ts` with zone CRUD endpoints\n- **fleet/store**: Create `zoneStore.ts` with Zustand for zone state\n- **fleet/hooks**: Create `useZones()`, `useZoneManagement()` hooks\n\n## Server (`server/src/`)\n- **Zone routes**: `GET /api/zones`, `POST /api/zones`, `PUT /api/zones/:id`, `DELETE /api/zones/:id`\n- **ZoneService**: Zone validation, overlap detection, coordinate handling\n- **Database**: Zone model with type (operational, exclusion, charging, staging), coordinates (polygon), color\n\n## Robot Client (`robot-agent/src/`)\n- **Zone awareness**: Update `tools/navigation.ts` to check zones before navigation\n- **Exclusion zones**: Prevent navigation into exclusion zones\n- **Current zone reporting**: Update `robot/state.ts` to report current zone (already has `zone` field)\n- **Zone events**: Emit events when entering/exiting zones\n\n**Key Files:**\n- Frontend: `app/src/features/fleet/components/FleetMap.tsx`, `app/src/features/fleet/types/fleet.types.ts`\n- Server: Create `server/src/routes/zone.routes.ts`, `server/src/services/ZoneService.ts`\n- Robot: `robot-agent/src/tools/navigation.ts`, `robot-agent/src/robot/state.ts`",
        "testStrategy": "Frontend: Test zone CRUD operations, test zone editor drawing, test zone display on map. Server: Test coordinate validation, test zone type enforcement, test overlap detection. Robot: Test zone-aware navigation, test exclusion zone blocking.",
        "priority": "medium",
        "dependencies": [
          "1",
          "9"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2025-12-23T00:08:31.659Z"
      },
      {
        "id": "14",
        "title": "User Settings & Preferences (Full Stack)",
        "description": "Build complete settings feature with user preferences, notifications, and appearance settings across frontend and server.",
        "details": "**Full-Stack Feature spanning Frontend + Server**\n\n## Frontend (`app/src/features/settings/`)\n- **Settings Page**: Create `SettingsPage` with tabbed navigation (appearance, notifications, security, profile)\n- **Settings Types**: Define `UserPreferences`, `NotificationSettings`, `AppSettings` in `settings.types.ts`\n- **Settings Components**: Create `GeneralSettings`, `NotificationSettings`, `AppearanceSettings`, `SecuritySettings`, `ProfileSettings`\n- **settings/api**: Create `settingsApi.ts` with `GET/PUT /api/settings`\n- **settings/store**: Expand beyond `themeStore.ts` to include all user preferences\n- **settings/hooks**: Create `useSettings()`, `useNotificationSettings()` hooks\n\n## Server (`server/src/`)\n- **Settings routes**: `GET /api/settings`, `PUT /api/settings`, notification preferences endpoints\n- **SettingsService**: User-specific settings management, defaults for new users\n- **Database**: UserSettings model tied to User\n\n**Note**: Robot client not affected - robot config via environment variables\n\n**Key Files:**\n- Frontend: `app/src/features/settings/store/themeStore.ts`, create `app/src/features/settings/types/settings.types.ts`\n- Server: Create `server/src/routes/settings.routes.ts`, `server/src/services/SettingsService.ts`\n- Server: Update `server/prisma/schema.prisma` with UserSettings model",
        "testStrategy": "Frontend: Test settings store persistence, test tab navigation, test each settings section updates store. Server: Test settings CRUD per user, test default settings for new users, test settings validation.",
        "priority": "medium",
        "dependencies": [
          "1",
          "2",
          "11"
        ],
        "status": "deferred",
        "subtasks": [],
        "updatedAt": "2025-12-22T21:21:44.009Z"
      },
      {
        "id": "15",
        "title": "NL Command Interpretation (Full Stack)",
        "description": "Implement natural language command interpretation with LLM integration, safety classification, and command history.",
        "details": "**Full-Stack Feature spanning Frontend + Server + Robot**\n\n## Frontend (`app/src/features/command/`)\n- **Wire to Server**: Update `commandApi.ts` to call server interpretation API instead of mock\n- **Command UI**: `CommandBar`, `CommandPreview`, `CommandConfirmation` already exist - wire to real API\n- **Command History**: Ensure `CommandHistory` component fetches from server API\n\n## Server (`server/src/`)\n- **Command routes**: `POST /api/command/interpret`, `GET /api/command/history`\n- **CommandInterpreter**: LLM integration (OpenAI/Anthropic) for NL interpretation\n- **Safety classification**: Classify commands as safe/caution/dangerous\n- **Confidence scoring**: Return confidence level (0-1) for interpretations\n- **Command history**: Store and retrieve command history with pagination\n\n## Robot Client (`robot-agent/src/`)\n- **Existing capability**: Already has Genkit/Gemini integration in `agent/agent-executor.ts`\n- **Server delegation**: Server can either interpret centrally or delegate to robot's Genkit\n- **Command execution**: Robot executes interpreted commands via existing tools\n\n**Key Files:**\n- Frontend: `app/src/features/command/api/commandApi.ts` - wire to server\n- Server: Create `server/src/routes/command.routes.ts`, `server/src/services/CommandInterpreter.ts`\n- Robot: `robot-agent/src/agent/agent-executor.ts` - already handles NL via Genkit",
        "testStrategy": "Frontend: Test command submission, test interpretation display, test history loading. Server: Test LLM interpretation, test confidence scores, test safety classification, test timeout handling. Robot: Test command execution via tools.",
        "priority": "high",
        "dependencies": [
          "1",
          "7"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-08T15:15:00.000Z"
      },
      {
        "id": "16",
        "title": "Database Persistence Layer (Server)",
        "description": "Add database persistence to the server - currently all data is in-memory and lost on restart.",
        "details": "**Server-Only Feature**\n\n## Server (`server/src/`)\n- **Database choice**: SQLite for development, PostgreSQL option for production\n- **ORM setup**: Add Prisma for TypeScript-first database access\n- **Schema design**: Create tables for:\n  - Users (auth)\n  - Robots (registration, status)\n  - Conversations (A2A protocol)\n  - Messages (conversation history)\n  - Tasks (A2A tasks)\n  - Alerts\n  - Zones\n  - UserSettings\n- **Migrations**: Set up Prisma migration system\n- **Service updates**: Replace in-memory Maps with database queries\n\n**Current State** (in-memory, data lost on restart):\n- `ConversationManager.ts` uses Maps for conversations, tasks, events, agents\n- `RobotManager.ts` uses Map for robots\n\n**Key Files:**\n- Create: `server/prisma/schema.prisma` - Full database schema\n- Create: `server/src/db/client.ts` - Prisma client setup\n- Update: `server/src/services/ConversationManager.ts` - Replace Maps with DB\n- Update: `server/src/services/RobotManager.ts` - Replace Maps with DB\n- Update: `server/package.json` - Add prisma, @prisma/client",
        "testStrategy": "Test data persists across server restarts. Test all CRUD operations work with database. Test migrations run successfully. Test connection handling. Test data integrity constraints.",
        "priority": "high",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2025-12-22T21:42:13.152Z"
      },
      {
        "id": "17",
        "title": "Testing Infrastructure (Full Stack)",
        "description": "Set up comprehensive testing infrastructure across frontend, server, and robot client.",
        "details": "**Full-Stack Feature spanning Frontend + Server + Robot**\n\n## Frontend (`app/src/`)\n- **Test framework**: Configure Vitest for unit testing\n- **Component testing**: React Testing Library setup\n- **API mocking**: MSW (Mock Service Worker) for API mocking\n- **Test utilities**: Create `renderWithProviders`, `mockStore` helpers\n- **Coverage**: Configure c8 for coverage reporting\n- **Initial tests**: Auth, robots, tasks stores and components\n\n## Server (`server/src/`)\n- **Test framework**: Vitest or Jest configuration\n- **API testing**: Supertest for HTTP endpoint testing\n- **Database mocking**: Test database or Prisma mocking\n- **Test utilities**: Auth helpers, request builders\n- **Coverage**: Coverage reporting configuration\n\n## Robot Client (`robot-agent/src/`)\n- **Test framework**: Vitest or Jest configuration\n- **Unit tests**: Tests for state management, telemetry generation\n- **Tool tests**: Tests for navigation, manipulation tools\n- **Mock A2A**: Mock server for A2A protocol testing\n\n**Key Files:**\n- Frontend: Create `app/vitest.config.ts`, `app/src/test/setup.ts`, `app/src/test/utils.tsx`, `app/src/mocks/handlers.ts`\n- Server: Create `server/vitest.config.ts`, `server/src/__tests__/`\n- Robot: Create `robot-agent/vitest.config.ts`, `robot-agent/src/__tests__/`",
        "testStrategy": "Meta: Ensure all test runners work with `npm test` in each package. Verify coverage reports generate. Test MSW intercepts API calls. Verify test utilities work. Ensure CI/CD integration possible.",
        "priority": "high",
        "dependencies": [
          "1"
        ],
        "status": "deferred",
        "subtasks": [],
        "updatedAt": "2025-12-22T21:19:35.639Z"
      },
      {
        "id": "18",
        "title": "Offline Support & Sync (Full Stack)",
        "description": "Implement offline capabilities with state caching, command queuing, and sync-on-reconnect.",
        "details": "**Full-Stack Feature spanning Frontend + Server**\n\n## Frontend (`app/src/`)\n- **Network detection**: Create `useOffline()` hook using navigator.onLine and online/offline events\n- **State caching**: Cache robot states, task states using IndexedDB or localStorage\n- **Command queue**: Implement command queue in `commandStore.ts` for offline execution\n- **Sync on reconnect**: Auto-sync queued commands when connection restores\n- **UI Components**: Create `OfflineIndicator`, `SyncStatus`, `QueuedCommandsPanel`\n\n## Server (`server/src/`)\n- **Sync endpoint**: `POST /api/sync` to receive queued commands\n- **Conflict resolution**: Handle conflicts when server state changed while offline\n- **Batch processing**: Process multiple queued commands efficiently\n\n**Note**: Robot client not affected - direct connection assumed\n\n**Key Files:**\n- Frontend: Create `app/src/shared/hooks/useOffline.ts`, `app/src/shared/components/OfflineIndicator.tsx`\n- Frontend: Update `app/src/features/command/store/commandStore.ts` - Add command queue\n- Server: Create sync endpoint for offline command processing",
        "testStrategy": "Frontend: Simulate network disconnection, verify cached data displays, test command queuing, test auto-sync on reconnect. Server: Test sync endpoint, test conflict resolution, test batch processing.",
        "priority": "medium",
        "dependencies": [
          "1",
          "3",
          "7"
        ],
        "status": "deferred",
        "subtasks": [],
        "updatedAt": "2025-12-22T21:20:12.700Z"
      },
      {
        "id": "19",
        "title": "Session Security (Full Stack)",
        "description": "Implement advanced session security with timeout detection, remember me, and account lockout.",
        "details": "**Full-Stack Feature spanning Frontend + Server**\n\n## Frontend (`app/src/features/auth/`)\n- **Session timeout**: Implement idle detection with auto-logout after inactivity\n- **Timeout warning**: Create session timeout warning modal before logout\n- **Remember me**: Add \"Remember Me\" checkbox to `LoginForm.tsx` (type already in `LoginRequest`)\n- **Idle detection**: Use `react-idle-timer` or custom hook in `AuthProvider.tsx`\n\n## Server (`server/src/`)\n- **Token refresh**: Implement refresh token rotation\n- **Session expiry**: Configure short-lived access tokens (15min) + longer refresh tokens\n- **Remember me**: Extend refresh token lifetime when remember me is checked (14 days vs 1 day)\n- **Account lockout**: Lock account after N failed login attempts (error type `ACCOUNT_LOCKED` exists)\n- **Lockout recovery**: Implement lockout timeout or admin unlock\n\n**Note**: Robot client not affected - robots use URL-based registration, no user auth\n\n**Key Files:**\n- Frontend: `app/src/features/auth/components/LoginForm.tsx`, `app/src/app/providers/AuthProvider.tsx`\n- Frontend: `app/src/features/auth/store/authStore.ts` - Add session timeout logic\n- Server: Update `server/src/services/AuthService.ts` - Add lockout logic\n- Server: Update `server/src/middleware/auth.middleware.ts` - Token validation",
        "testStrategy": "Frontend: Test session timeout triggers logout, test warning modal appears, test idle detection resets. Server: Test token refresh flow, test remember me extends session, test account locks after failed attempts, test lockout recovery.",
        "priority": "medium",
        "dependencies": [
          "1",
          "2",
          "11"
        ],
        "status": "deferred",
        "subtasks": [],
        "updatedAt": "2025-12-22T21:20:35.686Z"
      },
      {
        "id": "20",
        "title": "Structured Logging Infrastructure (Compliance)",
        "description": "Implement append-only structured logging with tamper-evident mechanisms for regulatory compliance across AI Act, GDPR, and Machinery Regulation.",
        "details": "**Regulatory Compliance Feature: AI Act Art. 12, GDPR Art. 30, MR Annex III**\n\n## Server (`server/src/`)\n- **Logging service**: Create `ComplianceLogService.ts` with:\n  - Append-only structured logging with hash chains for tamper evidence\n  - JSON format with ISO 8601 timestamps\n  - Fields: session_id, robot_id, operator_id, event_type, payload\n  - ML model version/hash logging for each AI operation\n  - Input-output matching records for AI decisions\n- **Log storage**: Implement write-once storage mechanism\n- **Log encryption**: AES-256-GCM for logs at rest\n- **Log access**: Role-based access with complete access audit trail\n- **Database**: Create ComplianceLog model with immutable flag\n\n## Robot Agent (`robot-agent/src/`)\n- **AI decision logging**: Log all Genkit AI decisions with context\n- **Safety decision recording**: Log safety-related decisions with confidence scores\n- **Movement logging**: Record navigation decisions for autonomous operations\n\n**Key Files:**\n- Server: Create `server/src/services/ComplianceLogService.ts`\n- Server: Create `server/src/routes/compliance-log.routes.ts`\n- Server: Update `server/prisma/schema.prisma` with ComplianceLog model\n- Robot: Update `robot-agent/src/agent/agent-executor.ts` for AI logging",
        "testStrategy": "Test log immutability (cannot modify existing logs). Test hash chain verification. Test AES-256 encryption at rest. Test role-based log access. Test AI decision logging captures all required fields. Verify timestamp accuracy and format.",
        "priority": "high",
        "dependencies": [
          "1",
          "16"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-10T14:07:23.594Z"
      },
      {
        "id": "21",
        "title": "Encryption & Secure Communication (Compliance)",
        "description": "Implement AES-256 encryption at rest and TLS 1.3 for all communications per GDPR Art. 32, NIS2, CRA, and EN 18031 requirements.",
        "details": "**Regulatory Compliance Feature: GDPR Art. 32, NIS2 Art. 21, CRA Annex I, EN 18031**\n\n## Server (`server/src/`)\n- **Database encryption**: Implement AES-256-GCM for SQLite/PostgreSQL data at rest\n- **TLS configuration**: Enforce TLS 1.3 for all HTTP/WebSocket connections\n- **Certificate management**: Create certificate rotation infrastructure\n- **Key management**: Implement secure key storage and rotation\n- **mTLS setup**: Configure mutual TLS for robot-to-server communication\n\n## Robot Agent (`robot-agent/src/`)\n- **TLS client**: Configure TLS 1.3 for server connections\n- **Device certificates**: Implement unique device certificate handling\n- **DTLS**: Configure DTLS for any UDP-based communications\n- **Key storage**: Secure local key storage\n\n## App (`app/src/`)\n- **HTTPS enforcement**: Ensure all API calls use HTTPS\n- **Certificate pinning**: Optional certificate pinning for mobile\n\n**Encryption Standards:**\n- AES-256-GCM for symmetric encryption\n- X25519 for key exchange\n- Ed25519 for signatures\n- SHA-256+ for hashing\n\n**Key Files:**\n- Server: Create `server/src/security/encryption.ts`\n- Server: Create `server/src/security/certificates.ts`\n- Robot: Update `robot-agent/src/api/server.ts` for TLS",
        "testStrategy": "Test TLS 1.3 is enforced (reject TLS 1.2 and below). Test database encryption/decryption. Test mTLS handshake between robot and server. Verify certificate rotation. Test key management operations.",
        "priority": "high",
        "dependencies": [
          "1",
          "16"
        ],
        "status": "deferred",
        "subtasks": [],
        "updatedAt": "2025-12-25T14:17:26.009Z"
      },
      {
        "id": "22",
        "title": "Multi-Factor Authentication (Compliance)",
        "description": "Implement FIDO2/WebAuthn and TOTP MFA per NIS2 Art. 21(2)(j) and CRA Annex I requirements.",
        "details": "**Regulatory Compliance Feature: NIS2 Art. 21(2)(j), CRA Annex I**\n\n## Server (`server/src/`)\n- **FIDO2/WebAuthn**: Primary MFA method implementation\n  - Registration flow for security keys\n  - Authentication flow with challenge/response\n  - Multiple key support per user\n- **TOTP fallback**: RFC 6238 TOTP as fallback option\n  - Secret generation and QR code display\n  - 6-digit code verification with time window\n- **Account lockout**: Lock after 5 failed MFA attempts\n- **Password requirements**: Minimum 12 characters, complexity rules\n- **First-use credential change**: Force password change on first login\n- **Privileged access management**: Enhanced auth for admin operations\n\n## App (`app/src/features/auth/`)\n- **MFA enrollment UI**: Security key registration, TOTP setup\n- **MFA challenge UI**: WebAuthn prompt, TOTP code input\n- **Recovery codes**: Display and manage recovery codes\n- **MFA settings**: Enable/disable MFA methods\n\n**Key Files:**\n- Server: Create `server/src/services/MFAService.ts`\n- Server: Update `server/src/routes/auth.routes.ts` with MFA endpoints\n- Server: Update `server/prisma/schema.prisma` with MFACredential model\n- App: Create `app/src/features/auth/components/MFAEnrollment.tsx`\n- App: Create `app/src/features/auth/components/MFAChallenge.tsx`",
        "testStrategy": "Test FIDO2 registration and authentication flow. Test TOTP code generation and verification. Test account lockout after failed attempts. Test password complexity requirements. Test recovery code usage.",
        "priority": "high",
        "dependencies": [
          "11",
          "19"
        ],
        "status": "deferred",
        "subtasks": [],
        "updatedAt": "2025-12-25T14:17:56.852Z"
      },
      {
        "id": "23",
        "title": "Device Identity & Secure Boot (Compliance)",
        "description": "Implement unique device certificates and secure boot verification per CRA Annex I, EN 18031, and MR Annex III.",
        "details": "**Regulatory Compliance Feature: CRA Annex I, EN 18031, MR Annex III**\n\n## Robot Agent (`robot-agent/src/`)\n- **Device certificates**: Generate and manage unique per-device X.509 certificates\n- **No default passwords**: Implement unique credential generation per device\n- **Secure boot verification**: Cryptographic signature verification at startup\n- **Software integrity**: Display installed software version and integrity status\n- **Anti-rollback**: Prevent installation of older vulnerable versions\n- **TPM integration**: Optional TPM 2.0 support for key storage\n- **Device identity API**: Expose device identity information securely\n\n## Server (`server/src/`)\n- **Device registry**: Store and validate device certificates\n- **Certificate issuance**: PKI infrastructure for device certificate management\n- **Device provisioning**: Secure device onboarding workflow\n- **Integrity verification**: Verify device software integrity on connection\n\n**Key Files:**\n- Robot: Create `robot-agent/src/security/device-identity.ts`\n- Robot: Create `robot-agent/src/security/secure-boot.ts`\n- Robot: Update `robot-agent/src/api/server.ts` for certificate auth\n- Server: Create `server/src/services/DeviceRegistryService.ts`\n- Server: Update `server/prisma/schema.prisma` with DeviceCertificate model",
        "testStrategy": "Test unique certificate generation per device. Test certificate-based authentication. Test software integrity verification. Test anti-rollback protection. Test device provisioning workflow.",
        "priority": "high",
        "dependencies": [
          "1"
        ],
        "status": "deferred",
        "subtasks": [],
        "updatedAt": "2025-12-25T14:18:54.850Z"
      },
      {
        "id": "24",
        "title": "Comprehensive Audit Trail System (Compliance)",
        "description": "Implement complete audit trail system with retention policies per AI Act Art. 18-19, MR Annex III, and GDPR Art. 30.",
        "details": "**Regulatory Compliance Feature: AI Act Art. 18-19, MR Annex III, GDPR Art. 30**\n\n## Server (`server/src/`)\n- **Audit events**: Create comprehensive AuditEventService\n  - Safety software version changes (5-year retention)\n  - AI safety decisions (1-year retention)\n  - Intervention evidence collection\n  - Movement decisions for autonomous ops\n  - All CRUD operations on sensitive data\n- **RoPA registry**: Records of Processing Activities\n  - Processing purposes\n  - Data categories\n  - Recipients and transfers\n  - Retention periods\n  - Security measures\n- **Log export API**: Deployer-accessible log export (6-month minimum)\n- **Provider documentation**: 10-year retention for technical docs\n- **Access audit**: Log all audit log access attempts\n\n## App (`app/src/`)\n- **Audit log viewer**: Admin interface for viewing audit trails\n- **Export functionality**: Download audit logs in various formats\n- **Filter and search**: Query audit logs by date, user, action type\n\n**Retention Matrix:**\n- Technical documentation: 10 years\n- Safety software versions: 5 years\n- AI decision logs: 1 year\n- Operational logs: 6 months\n\n**Key Files:**\n- Server: Create `server/src/services/AuditEventService.ts`\n- Server: Create `server/src/services/RoPAService.ts`\n- Server: Create `server/src/routes/audit.routes.ts`\n- Server: Update `server/prisma/schema.prisma` with AuditEvent, RoPA models\n- App: Create `app/src/features/admin/components/AuditLogViewer.tsx`",
        "testStrategy": "Test audit event capture for all required actions. Test retention policy enforcement. Test log export API. Test RoPA registry completeness. Test access audit logging. Verify data cannot be modified after creation.",
        "priority": "high",
        "dependencies": [
          "20",
          "16"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-10T15:54:46.003Z"
      },
      {
        "id": "25",
        "title": "Data Retention Engine (Compliance)",
        "description": "Implement automated data retention enforcement per AI Act Art. 19, GDPR Art. 5(1)(e), and MR Annex III.",
        "details": "**Regulatory Compliance Feature: AI Act Art. 19, GDPR Art. 5(1)(e), MR Annex III**\n\n## Server (`server/src/`)\n- **Retention policies**: Create RetentionPolicyService\n  - Configurable retention periods per data type\n  - Automated deletion scheduling (cron jobs)\n  - Exception handling for legal holds\n- **Data categories and periods:**\n  - Technical documentation: 10 years\n  - Safety software versions: 5 years per upload\n  - AI decision logs: 1 year minimum\n  - Deployer operational logs: 6 months\n  - CCTV/video (no incident): 72 hours-7 days\n  - Training records: 2 years\n  - First aid/incident records: 5 years\n- **Deletion audit**: Create proof-of-deletion logs\n- **Legal hold**: Suspend deletion for data under legal hold\n- **Archive tier**: Move data to cold storage before deletion\n\n**Key Files:**\n- Server: Create `server/src/services/RetentionPolicyService.ts`\n- Server: Create `server/src/jobs/retention-cleanup.ts`\n- Server: Create `server/src/routes/retention.routes.ts`\n- Server: Update `server/prisma/schema.prisma` with RetentionPolicy, LegalHold models",
        "testStrategy": "Test automated deletion at retention periods. Test deletion audit logging. Test legal hold prevents deletion. Test archive tier functionality. Test configurable retention per data type.",
        "priority": "high",
        "dependencies": [
          "16",
          "24"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-10T16:56:18.485Z"
      },
      {
        "id": "26",
        "title": "GDPR Rights Self-Service Portal (Compliance)",
        "description": "Implement GDPR data subject rights portal per Articles 15-22 (access, rectification, erasure, portability, objection).",
        "details": "**Regulatory Compliance Feature: GDPR Articles 15-22**\n\n## Server (`server/src/`)\n- **Art. 15 Access**: Self-service data export endpoint\n  - Compile all user data\n  - Third-party pixelation for CCTV\n  - 30-day response SLA tracking\n- **Art. 16 Rectification**: Data correction interface\n  - Edit interface for correctable data\n  - Audit trail of corrections\n- **Art. 17 Erasure**: Automated deletion workflows\n  - Right to be forgotten requests\n  - Exception handling (legal retention)\n- **Art. 18 Restriction**: Data flagging mechanism\n  - Processing limitation during disputes\n- **Art. 20 Portability**: Machine-readable export\n  - JSON/CSV export formats\n  - Automated data only\n- **Art. 21 Object**: Objection registration\n  - Re-assessment workflow\n- **Art. 22 ADM Safeguards**: Automated decision making\n  - Human intervention queue\n  - Contest workflow\n  - 72-hour acknowledgment SLA\n\n## App (`app/src/features/privacy/`)\n- **Privacy portal**: Self-service GDPR rights interface\n- **Data export**: Download personal data\n- **Deletion request**: Submit erasure requests\n- **Consent management**: View and manage consents\n- **Request tracking**: Track GDPR request status\n\n**Key Files:**\n- Server: Create `server/src/services/GDPRService.ts`\n- Server: Create `server/src/routes/gdpr.routes.ts`\n- Server: Update `server/prisma/schema.prisma` with GDPRRequest model\n- App: Create `app/src/features/privacy/` feature module\n- App: Create `app/src/features/privacy/components/PrivacyPortal.tsx`",
        "testStrategy": "Test data export completeness. Test erasure workflow including exceptions. Test portability export formats. Test request SLA tracking. Test human intervention queue for ADM. Test third-party data pixelation.",
        "priority": "high",
        "dependencies": [
          "11",
          "16"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-10T17:23:24.341Z"
      },
      {
        "id": "27",
        "title": "Incident Reporting Infrastructure (Compliance)",
        "description": "Implement incident detection and multi-authority reporting per AI Act Art. 73, GDPR Art. 33-34, NIS2 Art. 23, and CRA Art. 14.",
        "details": "**Regulatory Compliance Feature: AI Act Art. 73, GDPR Art. 33-34, NIS2 Art. 23, CRA Art. 14**\n\n## Server (`server/src/`)\n- **Incident detection**:\n  - Safety incident triggers (force/collision events)\n  - Security incident triggers (intrusion, auth failures)\n  - Anomaly detection in robot behavior\n- **Evidence preservation**:\n  - Immutable incident logging\n  - System state snapshots on incident\n- **Breach assessment**:\n  - Risk scoring matrix\n  - Automated severity classification\n- **Notification workflows** with authority-specific timelines:\n  - **AI Act**: 2/10/15 days depending on severity\n  - **GDPR**: 72 hours to DPA, immediate to data subjects if high risk\n  - **NIS2**: 24h early warning, 72h notification, 1 month final\n  - **CRA**: 24h for exploited vulnerabilities\n- **Timeline tracking**: Dashboard for deadline compliance\n- **Template system**: Pre-built notification templates per authority\n\n## App (`app/src/features/incidents/`)\n- **Incident dashboard**: View and manage incidents\n- **Reporting workflow**: Guide through notification process\n- **Timeline tracker**: Visual timeline of required actions\n- **Template editor**: Customize notification templates\n\n**Key Files:**\n- Server: Create `server/src/services/IncidentService.ts`\n- Server: Create `server/src/services/BreachAssessmentService.ts`\n- Server: Create `server/src/routes/incident.routes.ts`\n- Server: Update `server/prisma/schema.prisma` with Incident, IncidentNotification models\n- App: Create `app/src/features/incidents/` feature module",
        "testStrategy": "Test incident auto-detection triggers. Test evidence preservation immutability. Test severity classification. Test notification timeline tracking. Test template generation. Test multi-authority workflow.",
        "priority": "high",
        "dependencies": [
          "12",
          "24"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-11T00:46:34.007Z"
      },
      {
        "id": "28",
        "title": "Vulnerability Management & SBOM (Compliance)",
        "description": "Implement Software Bill of Materials and vulnerability management per CRA Art. 14 and Annex V.",
        "details": "**Regulatory Compliance Feature: CRA Art. 14, Annex V**\n\n## Server (`server/src/`)\n- **SBOM generation**: Automated Software Bill of Materials\n  - npm/package dependencies\n  - System libraries\n  - CycloneDX or SPDX format\n- **SBOM storage**: 10-year retention requirement\n- **Vulnerability tracking**:\n  - CVE monitoring for dependencies\n  - Severity classification (CVSS)\n  - Affected component mapping\n- **Disclosure program**: Coordinated vulnerability disclosure\n  - Security contact publication\n  - Disclosure timeline management\n- **Patch management**:\n  - Security update tracking\n  - Patch release workflow\n\n## Robot Agent (`robot-agent/src/`)\n- **Local SBOM**: Generate robot software SBOM\n- **Vulnerability status**: Report known vulnerabilities\n\n## App (`app/src/features/security/`)\n- **SBOM viewer**: Display component inventory\n- **Vulnerability dashboard**: Track CVEs and patches\n- **Disclosure portal**: Public vulnerability reporting\n\n**Key Files:**\n- Server: Create `server/src/services/SBOMService.ts`\n- Server: Create `server/src/services/VulnerabilityService.ts`\n- Server: Create `server/src/routes/security.routes.ts`\n- Robot: Create `robot-agent/src/security/sbom.ts`\n- App: Create `app/src/features/security/` feature module",
        "testStrategy": "Test SBOM generation completeness. Test CVE monitoring and alerting. Test vulnerability severity classification. Test SBOM export formats (CycloneDX, SPDX). Test disclosure workflow.",
        "priority": "high",
        "dependencies": [
          "1"
        ],
        "status": "deferred",
        "subtasks": [],
        "updatedAt": "2025-12-29T15:42:52.499Z"
      },
      {
        "id": "29",
        "title": "Secure Update System OTA (Compliance)",
        "description": "Implement secure over-the-air updates with signing, rollback, and approval workflows per CRA Art. 13 and MR Art. 10.",
        "details": "**Regulatory Compliance Feature: CRA Art. 13, MR Art. 10, Annex I**\n\n## Server (`server/src/`)\n- **Update packages**: Signed update package creation\n  - Ed25519 signature on all packages\n  - Version metadata and changelog\n- **Update distribution**:\n  - TLS 1.3 delivery only\n  - Integrity verification endpoint\n  - Update availability notification\n- **Approval workflows**:\n  - Safety update impact assessment\n  - Change control board approval for safety updates\n  - Dual approval for critical updates\n- **Rollback management**:\n  - Previous version storage\n  - Rollback trigger conditions\n\n## Robot Agent (`robot-agent/src/`)\n- **Secure update client**:\n  - Signature verification before install\n  - Atomic updates (all-or-nothing)\n  - Automatic rollback on failure\n  - Anti-rollback for security updates\n- **Update notifications**: User notification of available updates\n- **Opt-out support**: Allow update deferral (not default)\n\n## App (`app/src/features/updates/`)\n- **Update management**: Admin interface for updates\n- **Rollback controls**: Trigger rollback for fleet\n- **Approval UI**: Approve pending updates\n\n**Update Support Period: 5-10 years after market placement**\n\n**Key Files:**\n- Server: Create `server/src/services/UpdateService.ts`\n- Server: Create `server/src/routes/update.routes.ts`\n- Robot: Create `robot-agent/src/updates/secure-update.ts`\n- App: Create `app/src/features/updates/` feature module",
        "testStrategy": "Test package signing and verification. Test atomic update installation. Test rollback on failure. Test anti-rollback protection. Test approval workflow. Test TLS-only delivery.",
        "priority": "high",
        "dependencies": [
          "23",
          "28"
        ],
        "status": "deferred",
        "subtasks": [],
        "updatedAt": "2025-12-25T14:25:45.077Z"
      },
      {
        "id": "30",
        "title": "Enhanced E-Stop & Safety Monitoring (Compliance)",
        "description": "Enhance emergency stop and safety monitoring per MR Annex III, ISO 10218-1, and ISO/TS 15066 requirements.",
        "details": "**Regulatory Compliance Feature: MR Annex III, ISO 10218-1, ISO/TS 15066**\n\n## Robot Agent (`robot-agent/src/`)\n- **Safety monitoring at 1kHz**:\n  - Force/torque monitoring (Butterworth 100Hz filter)\n  - Speed limiting (250 mm/s TCP in manual mode)\n  - Position/proximity monitoring\n- **Communication timeout**: Safe state on server disconnect (1s default)\n- **Protective stop logging**: Full context capture on stop events\n- **Safety-rated monitored stop**: Stop Category 2 implementation\n- **Fail-safe**: Automatic protective stop on any safety system failure\n\n## Server (`server/src/`)\n- **E-stop endpoints**:\n  - Individual robot halt\n  - Fleet-wide emergency stop\n  - Geographic zone stop\n- **E-stop status**: Real-time status via WebSocket\n- **Reset workflow**: Deliberate separate start action required\n- **E-stop logging**: Capture all e-stop events with context\n\n## App (`app/src/features/safety/`)\n- **Enhanced E-stop button**: Per-robot and fleet-wide\n- **Zone-based stop**: Stop robots in specific zones\n- **Safety status dashboard**: Real-time safety metrics\n- **Stop confirmation**: Visual confirmation of stop state\n\n**ISO/TS 15066 Force Limits** (stored in config):\n- Skull/Forehead: 130N (contact not permissible)\n- Hands/Fingers: 140N quasi-static, 280N transient\n\n**Key Files:**\n- Robot: Update `robot-agent/src/tools/navigation.ts` for speed limits\n- Robot: Create `robot-agent/src/safety/force-monitor.ts`\n- Server: Create `server/src/routes/safety.routes.ts`\n- Server: Update WebSocket for e-stop status\n- App: Update `app/src/features/alerts/components/EmergencyStopButton.tsx`",
        "testStrategy": "Test e-stop response time (<100ms). Test fleet-wide stop. Test zone-based stop. Test reset workflow. Test communication timeout triggers safe state. Test force limit enforcement. Test protective stop logging.",
        "priority": "high",
        "dependencies": [
          "6"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2025-12-29T16:09:22.572Z"
      },
      {
        "id": "31",
        "title": "Human Oversight Dashboard (Compliance)",
        "description": "Implement human oversight mechanisms per AI Act Art. 14 including intervention, override, and explainability.",
        "details": "**Regulatory Compliance Feature: AI Act Art. 14**\n\n## App (`app/src/features/oversight/`)\n- **Intervention capabilities**:\n  - Stop/interrupt per robot and fleet-wide (Art. 14(4)(e))\n  - Manual task reassignment (Art. 14(4)(d))\n  - Local manual control mode activation\n- **Capability understanding** (Art. 14(4)(a)):\n  - Robot capabilities dashboard\n  - Current limitations display\n  - Confidence level indicators\n  - Anomaly indicators with visual alerts\n- **Output interpretation** (Art. 14(4)(c)):\n  - Decision explanation interface\n  - Input factors visualization\n  - Decision logic display\n  - Confidence scores\n  - Alternatives considered\n- **Automation bias prevention** (Art. 14(3)):\n  - Confirmation prompts for safety-critical decisions\n  - Periodic manual verification requirements\n  - Training module on automation bias\n\n## Server (`server/src/`)\n- **Oversight API**: Endpoints for all intervention actions\n- **Decision logging**: Store all oversight interactions\n- **Alert integration**: Configurable alert thresholds\n\n**Alert Response Times:**\n- Safety violation: 100ms\n- Anomaly detection: 1 second\n- System failure: Immediate\n\n**Key Files:**\n- App: Create `app/src/features/oversight/` feature module\n- App: Create `app/src/features/oversight/components/OversightDashboard.tsx`\n- App: Create `app/src/features/oversight/components/DecisionExplainer.tsx`\n- Server: Create `server/src/routes/oversight.routes.ts`",
        "testStrategy": "Test intervention actions complete within SLA. Test capability dashboard accuracy. Test decision explanation completeness. Test automation bias prevention prompts. Test alert response times.",
        "priority": "high",
        "dependencies": [
          "3",
          "6",
          "30"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-11T01:25:41.092Z"
      },
      {
        "id": "32",
        "title": "AI Explainability API (Compliance)",
        "description": "Implement AI decision explainability and transparency per AI Act Art. 13 and Art. 50.",
        "details": "**Regulatory Compliance Feature: AI Act Art. 13, Art. 50**\n\n## Robot Agent (`robot-agent/src/`)\n- **Decision explanation generation**:\n  - Capture input factors for each decision\n  - Extract decision logic from Genkit\n  - Calculate and report confidence scores\n  - Track alternatives considered\n- **AI disclosure**: Audio/visual indicator when AI is active\n\n## Server (`server/src/`)\n- **Explainability API** (Art. 13(1)):\n  - GET /api/decisions/:id/explanation\n  - Returns: input_factors, decision_logic, confidence_score, alternatives\n- **Performance metrics** (Art. 13(3)(b)):\n  - Precision/recall metrics\n  - Error rates tracking\n  - Drift indicators\n- **Documentation endpoints** (Art. 13(3)(a)):\n  - Intended purpose\n  - Accuracy metrics\n  - Known limitations\n  - Human oversight requirements\n- **Limitation disclosure** (Art. 13(3)(c)):\n  - Operating conditions\n  - Environmental constraints\n  - Population performance variations\n\n## App (`app/src/features/explainability/`)\n- **Decision viewer**: Visualize AI decision factors\n- **Performance dashboard**: Metrics and drift indicators\n- **Documentation portal**: Access system documentation\n\n**Key Files:**\n- Robot: Create `robot-agent/src/ai/explainability.ts`\n- Robot: Update `robot-agent/src/agent/agent-executor.ts` for explanation capture\n- Server: Create `server/src/services/ExplainabilityService.ts`\n- Server: Create `server/src/routes/explainability.routes.ts`\n- App: Create `app/src/features/explainability/` feature module",
        "testStrategy": "Test explanation generation for all decision types. Test confidence score calculation. Test alternatives tracking. Test performance metrics accuracy. Test AI disclosure indicator.",
        "priority": "high",
        "dependencies": [
          "15"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-08T16:30:00.000Z"
      },
      {
        "id": "33",
        "title": "Technical Documentation System (Compliance)",
        "description": "Implement technical documentation management per AI Act Annex IV, MR Annex IV, CRA Annex V, and RED Annex V.",
        "details": "**Regulatory Compliance Feature: AI Act Annex IV, MR Annex IV, CRA Annex V, RED Annex V**\n\n## Server (`server/src/`)\n- **AI System Technical File** (AI Act Annex IV):\n  - General description storage\n  - Design specifications\n  - Data requirements documentation\n  - Risk management records\n  - Testing/validation results\n  - Post-market monitoring plan\n- **Machinery Technical File** (MR Annex IV):\n  - Drawings and diagrams\n  - Risk assessment records\n  - Applied standards list\n  - Test reports\n  - Instructions storage\n- **Cybersecurity Documentation** (CRA Annex V):\n  - Security architecture docs\n  - Attack surface analysis\n  - SBOM integration\n  - Vulnerability handling procedures\n- **Risk assessment storage**:\n  - AI risk management (Art. 9)\n  - Machinery risk (ISO 12100)\n  - DPIA documents\n  - Cybersecurity assessments\n  - Occupational assessments\n- **Conformity declarations**: EU Declaration of Conformity management\n- **Document versioning**: Full audit trail with retention\n- **Public URL**: Publicly accessible conformity documents\n\n**Retention: 10 years after last unit placed on market**\n\n**Key Files:**\n- Server: Create `server/src/services/TechnicalDocService.ts`\n- Server: Create `server/src/routes/documentation.routes.ts`\n- Server: Update `server/prisma/schema.prisma` with TechnicalDoc, RiskAssessment models",
        "testStrategy": "Test document upload and versioning. Test 10-year retention enforcement. Test public URL access for conformity docs. Test risk assessment linkage. Test audit trail completeness.",
        "priority": "high",
        "dependencies": [
          "24"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-10T16:24:53.840Z"
      },
      {
        "id": "34",
        "title": "Compliance Monitoring Dashboard (Compliance)",
        "description": "Implement unified compliance monitoring dashboard tracking all regulatory frameworks and deadlines.",
        "details": "**Regulatory Compliance Feature: All Frameworks**\n\n## App (`app/src/features/compliance/`)\n- **Regulatory tracker**:\n  - Timeline of regulatory deadlines\n  - Status per framework (AI Act, MR, GDPR, NIS2, CRA, RED, DGUV)\n  - Gap analysis reporting\n- **Document management**:\n  - Document expiry alerts\n  - Certification status\n  - Missing document identification\n- **Training compliance** (DGUV):\n  - Training record tracking\n  - Annual refresh reminders\n  - Competence verification status\n- **Inspection schedules** (DGUV Vorschrift 3):\n  - Electrical inspection (every 4 years)\n  - Force verification (annual)\n  - Biomechanical verification (annual)\n- **Risk assessment tracking**:\n  - Due date monitoring\n  - Update trigger tracking\n\n## Server (`server/src/`)\n- **Compliance API**: Aggregate compliance status\n- **Alert generation**: Deadline and expiry alerts\n- **Report generation**: Compliance reports for auditors\n\n**Key Dates Tracked:**\n- April 2025: NIS2 registration\n- August 2025: RED EN 18031\n- January 2027: Machinery Regulation\n- August 2027: EU AI Act\n- December 2027: CRA\n\n**Key Files:**\n- App: Create `app/src/features/compliance/` feature module\n- App: Create `app/src/features/compliance/components/ComplianceDashboard.tsx`\n- Server: Create `server/src/services/ComplianceTrackerService.ts`\n- Server: Create `server/src/routes/compliance.routes.ts`",
        "testStrategy": "Test deadline tracking accuracy. Test alert generation for approaching deadlines. Test gap analysis reporting. Test training record management. Test inspection schedule tracking.",
        "priority": "medium",
        "dependencies": [
          "24",
          "27",
          "33"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-11T03:06:46.483Z"
      },
      {
        "id": "35",
        "title": "Human Approval Workflows (Compliance)",
        "description": "Implement human approval workflows for automated decisions per GDPR Art. 22 and AI Act Art. 14.",
        "details": "**Regulatory Compliance Feature: GDPR Art. 22, AI Act Art. 14**\n\n## Server (`server/src/`)\n- **Approval workflows**:\n  - Performance evaluation affecting worker: 48-hour SLA human review\n  - Shift/role change based on performance: Supervisor approval required\n  - Disciplinary action trigger: Manager sign-off mandatory (cannot proceed without)\n  - Safety parameter modification: Dual approval (safety officer + admin)\n  - Software update affecting safety: Change control board + rollback plan\n- **Worker rights** (EDPB WP251):\n  - Obtain human intervention endpoint\n  - Express viewpoint submission\n  - Contest decision workflow\n- **Approval tracking**:\n  - SLA monitoring\n  - Escalation paths\n  - Audit trail of approvals\n- **Meaningful oversight**:\n  - Active engagement verification\n  - No rubber-stamping detection\n  - Authority and competence verification\n\n## App (`app/src/features/approvals/`)\n- **Approval queue**: Pending approvals dashboard\n- **Review interface**: Decision review with context\n- **Escalation management**: Handle overdue approvals\n- **Worker portal**: Submit viewpoints, contest decisions\n\n**Key Files:**\n- Server: Create `server/src/services/ApprovalWorkflowService.ts`\n- Server: Create `server/src/routes/approval.routes.ts`\n- Server: Update `server/prisma/schema.prisma` with Approval, ApprovalChain models\n- App: Create `app/src/features/approvals/` feature module\n- App: Create `app/src/features/approvals/components/ApprovalQueue.tsx`",
        "testStrategy": "Test approval workflow routing. Test SLA enforcement and escalation. Test dual approval for safety changes. Test worker viewpoint submission. Test contest workflow. Test meaningful oversight verification.",
        "priority": "high",
        "dependencies": [
          "11",
          "31"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-11T02:06:37.138Z"
      },
      {
        "id": "36",
        "title": "Enhanced Process-Robot Task Delegation with Retry-Reassign",
        "description": "Enhance the process-to-robot task delegation system to automatically reassign failed tasks to different robots after exhausting retries on the same robot.",
        "details": "**Enhancement to Existing Process System**\n\nSee `docs/process-delegation-architecture.md` for full architecture.\n\n## Current Behavior\n- When a robot fails a task, ProcessManager retries on the same robot\n- After maxRetries, the entire process fails\n\n## Enhanced Behavior\n1. Retry on same robot first (configurable, e.g., 2 retries)\n2. After same-robot retries exhausted, reassign to different robot\n3. Track `failedRobotIds` to exclude from future assignments\n4. Continue until success OR all eligible robots exhausted\n\n## Implementation Steps\n\n### Step 1: Update Types\n**File**: `server/src/types/process.types.ts`\n- Add `failedRobotIds?: string[]` to `StepInstance`\n- Add `reassignmentCount?: number` to `StepInstance`\n- Add `maxReassignments?: number` to `StepTemplate`\n\n### Step 2: Update ProcessRepository\n**File**: `server/src/repositories/ProcessRepository.ts`\n- Add `addFailedRobotToStep(stepId, robotId)` method\n- Add `resetStepRetryCount(stepId)` method\n\n### Step 3: Enhance ProcessManager\n**File**: `server/src/services/ProcessManager.ts`\n- Modify `handleStepFailure()` to check reassignment eligibility\n- Add `shouldReassignStep(step)` helper\n- Add `reassignStep(step)` method\n- Emit `step:reassigned` event\n\n### Step 4: Update TaskDistributor\n**File**: `server/src/services/TaskDistributor.ts`\n- Modify `findEligibleRobots()` to accept `excludeRobotIds`\n- Pass exclude list when reassigning\n\n### Step 5: Add WebSocket Event\n**File**: `server/src/types/process.types.ts`\n- Add `StepReassignedEvent` type\n\n### Step 6: Update Frontend (Optional)\n**File**: `app/src/features/processes/types/process.types.ts`\n- Mirror type changes\n- Show reassignment info in TaskTimeline\n\n**Key Files:**\n- `server/src/types/process.types.ts`\n- `server/src/services/ProcessManager.ts`\n- `server/src/services/TaskDistributor.ts`\n- `server/src/repositories/ProcessRepository.ts`\n- `docs/process-delegation-architecture.md`",
        "testStrategy": "Test same-robot retry works (retry count increments). Test reassignment triggers after max same-robot retries. Test failedRobotIds excludes robots. Test process completes when reassigned robot succeeds. Test process fails when all robots exhausted. Test WebSocket events for reassignment.",
        "priority": "medium",
        "dependencies": [
          "4"
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": "37",
        "title": "VLA Database Schema Extension (VLA Infrastructure)",
        "description": "Extend the Prisma database schema with models for VLA training management including robot types, skills, datasets, training jobs, model versions, and deployments.",
        "details": "**VLA Integration Phase 1: Infrastructure Foundation**\n\nExtend the existing Prisma schema with models required for VLA training pipeline and fleet deployment.\n\n## Server (`server/prisma/schema.prisma`)\n- **RobotType model**: Define robot embodiment configurations\n  - `id`, `name`, `manufacturer`, `model` fields\n  - `actionDim`, `proprioceptionDim` for VLA action/observation dimensions\n  - `cameras` JSON field for camera configurations (name, resolution, fov)\n  - `capabilities` array for robot capabilities\n  - `limits` JSON for joint position/velocity/torque limits\n  - Relations to Dataset, SkillDefinition\n\n- **SkillDefinition model**: Define learnable robot skills\n  - `id`, `name`, `version`, `description` fields\n  - `parametersSchema` JSON for Zod-compatible parameter validation\n  - `preconditions`, `postconditions` JSON arrays\n  - `compatibleRobotTypes` relation\n  - `timeout`, `maxRetries` for execution constraints\n  - `status` enum: draft, published, deprecated, archived\n\n- **Dataset model**: Training datasets in LeRobot v3 format\n  - `id`, `name`, `description` fields\n  - `robotTypeId` foreign key to RobotType\n  - `skillId` optional foreign key to SkillDefinition\n  - `storagePath` for RustFS location\n  - `lerobotVersion`, `fps`, `totalFrames`, `totalDuration`\n  - `demonstrationCount`, `qualityScore` (0-100)\n  - `infoJson`, `statsJson` for LeRobot metadata\n  - `status` enum: uploading, validating, ready, failed\n\n- **TrainingJob model**: Training job queue entries\n  - `id`, `datasetId` foreign key\n  - `baseModel` enum: pi0, pi0_6, openvla, groot\n  - `fineTuneMethod` enum: lora, full, oft\n  - `hyperparameters` JSON (learning_rate, batch_size, epochs, lora_rank, warmup_steps)\n  - `gpuRequirements` JSON (count, memory, type)\n  - `status` enum: pending, queued, running, completed, failed, cancelled\n  - `progress` (0-100), `currentEpoch`, `totalEpochs`\n  - `metrics` JSON for training/validation loss curves\n  - `mlflowRunId`, `mlflowExperimentId`\n  - `startedAt`, `completedAt`, `errorMessage`\n  - `bullmqJobId` for queue tracking\n\n- **ModelVersion model**: Trained model artifacts\n  - `id`, `skillId` foreign key\n  - `trainingJobId` foreign key\n  - `version` semantic version string\n  - `artifactUri` for RustFS model location\n  - `checkpointUri` for intermediate checkpoints\n  - `trainingMetrics`, `validationMetrics` JSON\n  - `deploymentStatus` enum: staging, canary, production, archived\n  - `mlflowModelName`, `mlflowModelVersion`\n\n- **Deployment model**: Fleet deployment tracking\n  - `id`, `modelVersionId` foreign key\n  - `strategy` enum: canary, blue_green, rolling\n  - `targetRobotTypes` array, `targetZones` array\n  - `trafficPercentage` (0-100)\n  - `canaryConfig` JSON (stages, durations, thresholds)\n  - `rollbackThresholds` JSON (errorRate, latencyP99, failureRate)\n  - `status` enum: pending, deploying, canary, production, rolling_back, failed\n  - `deployedRobotIds` array, `failedRobotIds` array\n  - `startedAt`, `completedAt`\n\n## Server (`server/src/types/vla.types.ts`)\n- Export TypeScript interfaces matching all Prisma models\n- Define enums: BaseModel, FineTuneMethod, TrainingJobStatus, DeploymentStatus, DeploymentStrategy\n- Define JSON field types: Hyperparameters, GpuRequirements, CameraConfig, JointLimits\n\n## Server (`server/src/repositories/VLARepository.ts`)\n- Implement CRUD operations for all VLA models\n- Implement query methods: getReadyDatasets, getPendingJobs, getActiveDeployments\n- Implement relation loading methods\n\n**Key Files:**\n- `server/prisma/schema.prisma` - Add 6 new models with relations\n- `server/src/types/vla.types.ts` - TypeScript type definitions\n- `server/src/repositories/VLARepository.ts` - Data access layer\n- Migration file: `server/prisma/migrations/YYYYMMDD_add_vla_models/migration.sql`",
        "testStrategy": "Validate schema migrations run successfully with `npx prisma migrate dev`. Test CRUD operations for all 6 new models. Verify foreign key relationships and cascade behaviors. Test enum field validation. Verify JSON field serialization/deserialization. Test unique constraints and indexes.",
        "priority": "high",
        "dependencies": [
          "16"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-12T22:17:26.137Z"
      },
      {
        "id": "38",
        "title": "NATS JetStream Training Job Queue (VLA Infrastructure)",
        "description": "Implement asynchronous training job management using NATS JetStream for job queuing with WorkQueue retention, KV stores for progress tracking, and real-time WebSocket updates via pub/sub.",
        "details": "**VLA Integration Phase 1: Infrastructure Foundation**\n\nSet up NATS JetStream for managing VLA training jobs with real-time progress tracking. See `docs/nats-rustfs.md` for complete implementation reference.\n\n## Infrastructure (`docker-compose.yml`)\n- Add NATS Alpine service with JetStream enabled\n  - Port 4222 (client), 8222 (monitoring)\n  - Volume for JetStream storage: `nats-data:/data/jetstream`\n  - Health check with `wget -q --spider http://localhost:8222/healthz`\n  - JetStream config: `max_mem: 4G`, `max_file: 100G`\n\n## Server (`server/src/messaging/nats-client.ts`)\n- **NATS connection**: Environment-based configuration\n  - `NATS_SERVERS`, `NATS_USER`, `NATS_PASS` env vars\n  - Automatic reconnection with exponential backoff\n  - Connection status monitoring and events\n  - JetStream and JetStreamManager initialization\n- **Connection helpers**:\n  - `getKV(name)`: Access KV store\n  - `publish(subject, data)`: Publish message\n  - `jetPublish(subject, data, options)`: Publish with deduplication\n  - `request(subject, data)`: Request/reply pattern\n\n## Server (`server/src/messaging/streams.ts`)\n- **TRAINING_JOBS stream**: WorkQueue retention policy\n  - Subjects: `jobs.training.finetune`, `jobs.training.evaluate`, `jobs.training.export`\n  - 3 replicas, 7-day max age, 100MB max size\n  - 5-minute deduplication window\n- **Consumer**: `training-workers` with explicit ack\n  - 30-minute ack wait for long training jobs\n  - Max 3 delivery attempts\n  - Exponential backoff: 30s, 5min, 30min\n- **DEAD_LETTER_QUEUE stream**: Capture failed jobs\n\n## Server (`server/src/messaging/kv-stores.ts`)\n- **JOB_PROGRESS KV**: Real-time job progress tracking\n  - 10 revision history, 1-hour TTL\n  - Keys: `job.{jobId}` with status, progress, metrics\n  - Watch capability for real-time updates\n- **MODEL_REGISTRY KV**: Model metadata\n  - 50 revision history for versioning\n- **FLEET_CONFIG KV**: Fleet-wide configuration\n\n## Server (`server/src/messaging/job-queue.ts`)\n- **JetStreamJobQueue class**:\n  - `addJob(type, data, options)`: Submit job with priority and deduplication\n  - `process(processor, concurrency)`: Consume and process jobs\n  - `getJobProgress(jobId)`: Read from KV store\n  - `cancelJob(jobId)`: Signal cancellation\n  - `watchJobProgress(jobId, callback)`: Real-time KV watch\n- **Job context**:\n  - `updateProgress(progress, message)`: Update KV\n  - `heartbeat()`: Extend ack deadline\n  - `isCancelled()`: Check cancellation flag\n\n## Server (`server/src/services/TrainingJobService.ts`)\n- **Job submission**: `submitJob(datasetId, config)` returns TrainingJob\n  - Validate dataset exists and is ready\n  - Validate hyperparameters against schema\n  - Create TrainingJob record with status=pending\n  - Add to JetStream with priority and msgID for deduplication\n  - Initialize progress in JOB_PROGRESS KV\n  - Return job with natsJobId\n- **Job lifecycle management**:\n  - `getJob(id)`: Get job with current status from KV\n  - `cancelJob(id)`: Signal worker via cancellation flag\n  - `retryJob(id)`: Re-publish to stream\n  - `getJobLogs(id)`: Return training logs\n- **Progress tracking**:\n  - Watch JOB_PROGRESS KV for real-time updates\n  - Broadcast changes to WebSocket subscribers\n- **Queue status**:\n  - `getQueueStats()`: Query stream info for counts\n  - `getActiveJobs()`: List from JOB_PROGRESS KV\n\n## Server (`server/src/routes/training.routes.ts`)\n- `POST /api/training/jobs` - Submit new training job\n- `GET /api/training/jobs` - List jobs with filtering (status, datasetId)\n- `GET /api/training/jobs/:id` - Get job details with metrics\n- `POST /api/training/jobs/:id/cancel` - Cancel job\n- `POST /api/training/jobs/:id/retry` - Retry failed job\n- `GET /api/training/queue/stats` - Queue statistics\n\n## Server (`server/src/websocket/training.ws.ts`)\n- Create training event channel on existing WebSocket\n- Subscribe to JOB_PROGRESS KV watch\n- Emit events: `training:job:created`, `training:job:started`, `training:job:progress`, `training:job:completed`, `training:job:failed`\n- Event payload: `{ jobId, status, progress, metrics, eta }`\n- Subscribe clients to specific job updates\n\n**Key Files:**\n- `server/src/messaging/nats-client.ts` - NatsClient singleton with JetStream\n- `server/src/messaging/streams.ts` - Stream definitions (TRAINING_JOBS)\n- `server/src/messaging/kv-stores.ts` - KV store setup (JOB_PROGRESS)\n- `server/src/messaging/job-queue.ts` - JetStreamJobQueue class\n- `server/src/services/TrainingJobService.ts` - Job management business logic\n- `server/src/routes/training.routes.ts` - REST API endpoints\n- `server/src/websocket/training.ws.ts` - Real-time event broadcasting\n- `docker-compose.yml` - Add NATS service\n- `.env.example` - Add NATS_* environment variables",
        "testStrategy": "Test NATS connection and reconnection handling. Test job submission creates database record and JetStream message with deduplication. Test priority ordering via consumer fetch. Test progress events reach WebSocket subscribers within 1 second via KV watch. Test job cancellation signals worker. Test retry re-publishes with incremented attempt count. Test stream stats accuracy. Mock NATS for unit tests using nats-server embedded.",
        "priority": "high",
        "dependencies": [
          "37"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-12T22:46:44.788Z"
      },
      {
        "id": "39",
        "title": "RustFS Object Storage Integration (VLA Infrastructure)",
        "description": "Integrate RustFS S3-compatible distributed storage for training datasets and model artifacts with presigned URLs for large file uploads, erasure coding for durability, and bucket lifecycle management.",
        "details": "**VLA Integration Phase 1: Infrastructure Foundation**\n\nSet up RustFS for scalable storage of training data and model checkpoints. See `docs/nats-rustfs.md` for complete implementation reference.\n\n## Infrastructure (`docker-compose.yml`)\n- Add RustFS cluster (4 nodes for EC:4 erasure coding)\n  - Ports: 9000 (API), 9001 (Console) per node\n  - Volumes: `rustfs-{1..4}-data:/data`\n  - Environment: `RUSTFS_ACCESS_KEY`, `RUSTFS_SECRET_KEY`\n  - Health check with `curl -f http://localhost:9001/rustfs/console/index.html`\n  - Command: `server http://rustfs-{1...4}:9000/data --console-address \":9001\"`\n- Add nginx load balancer for HA\n  - Port 9090 exposed\n  - Upstream to all 4 RustFS nodes\n  - Config: `config/nginx-rustfs.conf`\n- Create initial buckets via init container:\n  - `training-datasets` - LeRobot format training data\n  - `model-checkpoints` - Training checkpoint snapshots\n  - `production-models` - Deployed ONNX models (versioned)\n  - `robot-logs` - Telemetry archives and incident logs\n- Set lifecycle rules:\n  - `model-checkpoints/temp/` - 90 day expiry\n  - `robot-logs/debug/` - 30 day expiry\n\n## Server (`server/src/storage/rustfs-client.ts`)\n- **RustFS client configuration**:\n  - Use `@aws-sdk/client-s3` (S3-compatible)\n  - Use `@aws-sdk/s3-request-presigner` for presigned URLs\n  - Use `@aws-sdk/lib-storage` for multipart uploads\n  - Environment config: `RUSTFS_ENDPOINT`, `RUSTFS_ACCESS_KEY`, `RUSTFS_SECRET_KEY`\n  - Force path style: true\n  - Connection validation on startup\n  - Retry logic for transient failures\n- **RustFSClient class methods**:\n  - `upload(bucket, key, body, options)`: Upload with progress callback\n  - `download(bucket, key)`: Download as Buffer\n  - `getStream(bucket, key)`: Download as Readable stream\n  - `delete(bucket, key)`: Delete object\n  - `exists(bucket, key)`: Check existence\n  - `getMetadata(bucket, key)`: Get size, contentType, lastModified\n  - `list(bucket, options)`: List objects with pagination\n  - `listAll(bucket, prefix)`: Async generator for all objects\n  - `getPresignedDownloadUrl(bucket, key, expiresIn)`: Presigned download\n  - `getPresignedUploadUrl(bucket, key, expiresIn, contentType)`: Presigned upload\n  - `copy(src, dest)`: Copy object\n  - `move(src, dest)`: Move object\n\n## Server (`server/src/storage/model-storage.ts`)\n- **ModelStorageClient class**:\n  - Bucket constants: datasets, checkpoints, models, logs\n  - `uploadDataset(name, version, data, metadata)`: Store training dataset\n  - `getDatasetStream(name, version)`: Stream dataset\n  - `uploadCheckpoint(jobId, epoch, data, metrics)`: Store checkpoint\n  - `listCheckpoints(jobId)`: List job checkpoints\n  - `uploadProductionModel(modelName, version, onnxBuffer, metadata)`: Deploy model\n  - `getModelDownloadUrl(modelName, version, expiry)`: Presigned URL\n  - `listModelVersions(modelName)`: List versions\n  - `uploadRobotLog(robotId, date, logType, data)`: Archive logs\n\n## Server (`server/src/routes/storage.routes.ts`)\n- `POST /api/storage/presign` - Get presigned upload URL\n  - Body: `{ bucket, key, contentType, size }`\n  - Validate size limits (datasets: 50GB, models: 10GB)\n- `POST /api/storage/datasets/:id/complete` - Mark dataset upload complete\n  - Triggers validation and quality scoring\n- `GET /api/storage/datasets/:id/download` - Get presigned download URL\n- `POST /api/storage/models/:id/upload` - Upload model artifact\n- `GET /api/storage/models/:id/download` - Get model download URL\n- `GET /api/storage/stats` - Storage statistics\n- `DELETE /api/storage/temp/:key` - Cancel incomplete upload\n\n## Server (`server/src/jobs/storage-cleanup.ts`)\n- Scheduled job (daily 3 AM): Clean temp uploads\n- Remove uploads older than 24 hours from temp prefix\n- Log cleanup statistics\n\n**Key Files:**\n- `server/src/storage/rustfs-client.ts` - RustFSClient using AWS SDK S3\n- `server/src/storage/model-storage.ts` - ModelStorageClient class\n- `server/src/routes/storage.routes.ts` - Storage API endpoints\n- `server/src/jobs/storage-cleanup.ts` - Scheduled cleanup job\n- `docker-compose.yml` - Add RustFS cluster (4 nodes)\n- `config/nginx-rustfs.conf` - Load balancer configuration\n- `.env.example` - Add RUSTFS_* environment variables",
        "testStrategy": "Test presigned URL generation and expiry (reject expired URLs). Test multipart upload for files >5MB using @aws-sdk/lib-storage. Test LeRobot structure validation (reject missing info.json). Test file size limit enforcement. Test bucket lifecycle rules. Test cleanup job removes only old temp files. Test download URL works for stored objects. Test erasure coding survives node failure. Use RustFS in Docker for integration tests.",
        "priority": "high",
        "dependencies": [
          "37"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-12T23:05:04.782Z"
      },
      {
        "id": "40",
        "title": "MLflow Model Registry Integration (VLA Infrastructure)",
        "description": "Integrate MLflow for experiment tracking, model versioning, and deployment management with staging/production/canary aliases.",
        "details": "**VLA Integration Phase 1: Infrastructure Foundation**\n\nSet up MLflow for comprehensive model lifecycle management.\n\n## Infrastructure (`docker-compose.yml`)\n- Add MLflow service\n  - Image: `ghcr.io/mlflow/mlflow:v2.10.0`\n  - Port: 5000\n  - Backend store: PostgreSQL (shared with main db or separate)\n  - Artifact store: RustFS (`s3://models`) - uses storage from Task 39\n  - Environment: `MLFLOW_S3_ENDPOINT_URL=${RUSTFS_ENDPOINT}`, `AWS_ACCESS_KEY_ID=${RUSTFS_ACCESS_KEY}`, `AWS_SECRET_ACCESS_KEY=${RUSTFS_SECRET_KEY}`\n  - Command: `mlflow server --host 0.0.0.0 --backend-store-uri postgresql://... --default-artifact-root s3://models`\n\n## Server (`server/src/services/MLflowService.ts`)\n- **MLflow REST client**: Implement Node.js client for MLflow REST API\n  - Base URL from `MLFLOW_TRACKING_URI` env var\n  - Error handling with typed responses\n  - Retry logic for transient failures\n- **Experiment management**:\n  - `createExperiment(name, tags)`: Create training experiment\n  - `getExperiment(id)`: Get experiment details\n  - `listExperiments()`: List all experiments\n- **Run management**:\n  - `createRun(experimentId, tags)`: Start training run\n  - `logParams(runId, params)`: Log hyperparameters\n  - `logMetrics(runId, metrics, step)`: Log training metrics\n  - `logArtifact(runId, localPath, artifactPath)`: Upload artifact\n  - `endRun(runId, status)`: Mark run complete/failed\n  - `getRun(runId)`: Get run with metrics/params/artifacts\n- **Model registry**:\n  - `createRegisteredModel(name, tags)`: Register model\n  - `createModelVersion(modelName, source, runId)`: Add version\n  - `setModelVersionTag(name, version, key, value)`: Add tags\n  - `transitionModelVersionStage(name, version, stage)`: Move to staging/production\n  - `getLatestModelVersion(name, stages)`: Get version by stage\n  - `setModelAlias(name, alias, version)`: Set canary alias\n- **Metric queries**:\n  - `compareRuns(runIds, metrics)`: Compare training runs\n  - `getMetricHistory(runId, metricKey)`: Get metric over time\n\n## Server (`server/src/routes/models.routes.ts`)\n- `POST /api/models/experiments` - Create experiment\n- `GET /api/models/experiments` - List experiments\n- `GET /api/models/experiments/:id/runs` - List runs in experiment\n- `POST /api/models/registry` - Register model\n- `GET /api/models/registry/:name/versions` - List versions\n- `PUT /api/models/registry/:name/versions/:version/stage` - Transition stage\n- `GET /api/models/registry/:name/latest` - Get latest by stage\n- `GET /api/models/compare` - Compare runs by metrics\n- `GET /api/models/runs/:id/metrics/:key` - Get metric history\n\n**Key Files:**\n- `server/src/services/MLflowService.ts` - MLflow REST API client\n- `server/src/routes/models.routes.ts` - Model registry API endpoints\n- `server/src/types/mlflow.types.ts` - MLflow API response types\n- `docker-compose.yml` - Add MLflow service\n- `.env.example` - Add MLFLOW_TRACKING_URI",
        "testStrategy": "Test experiment creation and listing. Test run creation with params/metrics logging. Test artifact upload to RustFS via MLflow. Test model registration and versioning. Test stage transitions (None  Staging  Production). Test alias management for canary deployments. Test metric comparison across runs. Mock MLflow API for unit tests, use real MLflow for integration tests.",
        "priority": "high",
        "dependencies": [
          "37",
          "39"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-12T23:40:11.496Z"
      },
      {
        "id": "41",
        "title": "Dataset Management API (VLA Training)",
        "description": "Implement LeRobot v3 dataset management API with upload validation, quality scoring, HuggingFace Hub integration, and normalization statistics computation.",
        "details": "**VLA Integration Phase 2: Training Pipeline**\n\nBuild comprehensive dataset management for VLA training with LeRobot v3 format support.\n\n## Server (`server/src/types/dataset.types.ts`)\n- **LeRobot v3 types**:\n  - `LeRobotInfo`: codebase_version, robot_type, fps, video, features (state, action shapes)\n  - `LeRobotStats`: mean, std, min, max per feature\n  - `LeRobotEpisode`: episode_index, length, timestamp fields\n- **Dataset DTOs**:\n  - `CreateDatasetDto`: name, description, robotTypeId, skillId\n  - `DatasetResponse`: full dataset with relations\n  - `DatasetListQuery`: filters for robotType, skill, status\n\n## Server (`server/src/services/DatasetService.ts`)\n- **Dataset CRUD**:\n  - `create(dto)`: Create dataset record with status=uploading\n  - `get(id)`: Get dataset with robotType and skill relations\n  - `list(query)`: Paginated list with filters\n  - `update(id, dto)`: Update name/description\n  - `delete(id)`: Delete record and RustFS storage\n- **Upload workflow**:\n  - `initiateUpload(id)`: Return presigned URL from StorageService\n  - `completeUpload(id)`: Trigger validation pipeline\n  - `validateStructure(id)`: Parse and validate LeRobot v3 format\n    - Check info.json exists and valid\n    - Check stats.json exists (or trigger computation)\n    - Validate episodes directory structure\n    - Count demonstrations and total duration\n- **Quality scoring** (0-100):\n  - Demonstration count (0-40 points): >50 demos = max\n  - Duration (0-30 points): >1 hour = max\n  - Diversity estimate (0-20 points): based on episode variance\n  - Format compliance (0-10 points): all required files present\n- **Normalization stats**:\n  - `computeStats(id)`: Queue Python worker to compute stats.json\n  - `getStats(id)`: Return cached normalization statistics\n- **HuggingFace integration** (optional):\n  - `importFromHub(repoId)`: Clone dataset from HuggingFace\n  - `exportToHub(id, repoId)`: Push dataset to HuggingFace\n\n## Server (`server/src/routes/datasets.routes.ts`)\n- `POST /api/datasets` - Create dataset record\n- `GET /api/datasets` - List datasets with filters\n- `GET /api/datasets/:id` - Get dataset details\n- `PUT /api/datasets/:id` - Update dataset metadata\n- `DELETE /api/datasets/:id` - Delete dataset\n- `POST /api/datasets/:id/upload/initiate` - Get upload URL\n- `POST /api/datasets/:id/upload/complete` - Mark upload complete\n- `POST /api/datasets/:id/compute-stats` - Trigger stats computation\n- `GET /api/datasets/:id/stats` - Get normalization stats\n- `POST /api/datasets/import-hub` - Import from HuggingFace\n\n## Server (`server/src/workers/dataset-validation.worker.ts`)\n- NATS consumer worker for async validation\n- Parse LeRobot info.json/stats.json\n- Update dataset record with parsed metadata\n- Set status to ready or failed\n\n**Key Files:**\n- `server/src/types/dataset.types.ts` - LeRobot v3 type definitions\n- `server/src/services/DatasetService.ts` - Dataset management logic\n- `server/src/routes/datasets.routes.ts` - REST API endpoints\n- `server/src/workers/dataset-validation.worker.ts` - Async validation worker",
        "testStrategy": "Test dataset creation with valid LeRobot v3 format (should parse metadata). Test validation rejects invalid formats (missing info.json  status=failed). Test quality score calculation (verify point allocation). Test cascade delete removes RustFS storage. Test HuggingFace import if configured. Test list filtering by robotType and skill. Test stats computation queues worker.",
        "priority": "high",
        "dependencies": [
          "38",
          "39"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-13T00:11:36.262Z"
      },
      {
        "id": "42",
        "title": "Training Job Orchestration (VLA Training)",
        "description": "Implement training job submission, hyperparameter validation, GPU allocation tracking, Python worker communication via HTTP callbacks, and progress monitoring with ETA estimation.",
        "details": "**VLA Integration Phase 2: Training Pipeline**\n\nBuild the orchestration layer connecting the Node.js server to Python training workers.\n\n## Server (`server/src/services/TrainingOrchestrator.ts`)\n- **Job creation**:\n  - `createJob(datasetId, config)`: Validate and queue training job\n    - Validate dataset exists and status=ready\n    - Validate hyperparameters against schema (Zod)\n    - Validate GPU requirements feasibility\n    - Check dataset robotType compatible with base model\n    - Create TrainingJob record\n    - Create MLflow run via MLflowService\n    - Queue to NATS JetStream with priority\n- **Hyperparameter validation**:\n  - `learning_rate`: 1e-6 to 1e-3 range\n  - `batch_size`: 1 to 64, power of 2\n  - `epochs`: 1 to 100\n  - `lora_rank`: 4, 8, 16, 32, 64 (if lora method)\n  - `warmup_steps`: 0 to epochs * steps_per_epoch\n- **GPU allocation**:\n  - `getGpuAvailability()`: Query cloud provider API\n  - `estimateTrainingDuration(datasetId, config)`: Based on dataset size and epochs\n  - Support spot instance hints for cost optimization\n- **Job lifecycle**:\n  - `startJob(id)`: Mark as running, set startedAt\n  - `updateProgress(id, progress, metrics)`: Store progress and loss curves\n  - `completeJob(id, artifactUri)`: Mark complete, create ModelVersion\n  - `failJob(id, error)`: Mark failed with error message\n  - `cancelJob(id)`: Signal worker to stop, mark cancelled\n\n## Server (`server/src/routes/training.routes.ts`) - Worker callbacks\n- `POST /api/training/workers/heartbeat` - Worker alive check\n  - Body: `{ jobId, gpuUtil, memoryUtil }`\n- `POST /api/training/workers/progress` - Progress update\n  - Body: `{ jobId, epoch, step, trainLoss, valLoss, learningRate }`\n  - Calculate ETA based on step rate\n- `POST /api/training/workers/complete` - Training complete\n  - Body: `{ jobId, artifactUri, finalMetrics }`\n  - Trigger model registration in MLflow\n- `POST /api/training/workers/failed` - Training failed\n  - Body: `{ jobId, error, lastCheckpoint }`\n- `POST /api/training/workers/checkpoint` - Checkpoint saved\n  - Body: `{ jobId, epoch, checkpointUri }`\n\n## Server (`server/src/workers/training.worker.ts`)\n- NATS consumer worker that bridges to Python\n- On job received:\n  - Prepare job config JSON\n  - Either: HTTP POST to Python training service\n  - Or: Spawn Python process with config file\n- Monitor for completion/failure callbacks\n\n## ETA Calculation\n- Track step timestamps\n- Calculate rolling average step duration\n- Project remaining time: `(totalSteps - currentStep) * avgStepDuration`\n- Update ETA on each progress callback\n\n**Key Files:**\n- `server/src/services/TrainingOrchestrator.ts` - Job orchestration logic\n- `server/src/routes/training.routes.ts` - Worker callback endpoints (extend)\n- `server/src/workers/training.worker.ts` - NATS to Python bridge\n- `server/src/types/training.types.ts` - Training config and callback types",
        "testStrategy": "Test job creation with valid config creates DB record and MLflow run. Test hyperparameter validation rejects out-of-range values. Test progress callbacks update job record and emit WebSocket events. Test ETA calculation accuracy (within 20% of actual). Test completion creates ModelVersion linked to job. Test cancellation removes from queue if pending, signals worker if running.",
        "priority": "high",
        "dependencies": [
          "38",
          "41"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-13T00:29:25.589Z"
      },
      {
        "id": "43",
        "title": "Training Frontend (VLA Training)",
        "description": "Build React feature module for VLA training management with dataset upload/browsing, training job wizard, real-time progress monitoring, and model comparison dashboard.",
        "details": "**VLA Integration Phase 2: Training Pipeline**\n\nCreate comprehensive training management UI following existing app patterns.\n\n## App (`app/src/features/training/`)\n- **Feature structure**:\n  ```\n  training/\n   types/training.types.ts\n   api/trainingApi.ts\n   store/trainingStore.ts\n   hooks/\n      useDatasets.ts\n      useTrainingJobs.ts\n      useModelVersions.ts\n   components/\n      DatasetList.tsx\n      DatasetUpload.tsx\n      DatasetCard.tsx\n      TrainingJobForm.tsx\n      TrainingProgress.tsx\n      LossCurveChart.tsx\n      ModelCompare.tsx\n      ModelVersionList.tsx\n      HyperparameterForm.tsx\n   pages/\n       DatasetsPage.tsx\n       TrainingPage.tsx\n       ModelsPage.tsx\n  ```\n\n## Types (`training.types.ts`)\n- Mirror server types: Dataset, TrainingJob, ModelVersion, Deployment\n- Define form types: CreateDatasetForm, TrainingJobConfig\n- Define UI state types: UploadProgress, TrainingProgress\n\n## API (`trainingApi.ts`)\n- Dataset endpoints: create, list, get, delete, initiateUpload, completeUpload\n- Training endpoints: createJob, listJobs, getJob, cancelJob\n- Model endpoints: listVersions, compareModels, getMetrics\n\n## Store (`trainingStore.ts`)\n- Zustand store with:\n  - `datasets`: Map of datasets by ID\n  - `trainingJobs`: Map of jobs by ID\n  - `activeUploads`: Track upload progress\n  - `activeTraining`: Currently running jobs with live progress\n- Actions: fetchDatasets, createDataset, startTraining, updateJobProgress\n\n## Components\n\n### DatasetList.tsx\n- Grid/list toggle view\n- Filter by robotType, skill, status\n- Sort by date, quality score\n- Quality score badge (color-coded)\n- Delete action with confirmation\n\n### DatasetUpload.tsx\n- Drag-and-drop zone with progress\n- File type validation (.tar.gz, .zip)\n- Size display and validation\n- LeRobot format guidance tooltip\n- Resume incomplete uploads\n\n### TrainingJobForm.tsx\n- Step wizard:\n  1. Select dataset (with preview)\n  2. Choose base model (0.6, OpenVLA)\n  3. Configure hyperparameters (with presets)\n  4. GPU requirements\n  5. Review and submit\n- Preset buttons: \"Quick train\", \"Full train\", \"Fine-tune only\"\n- Estimated cost and duration display\n\n### TrainingProgress.tsx\n- Real-time progress bar\n- Current epoch / total epochs\n- ETA countdown\n- GPU utilization gauge\n- Cancel button with confirmation\n- WebSocket subscription for live updates\n\n### LossCurveChart.tsx\n- Recharts line chart\n- Train loss and validation loss curves\n- Zoomable x-axis (epochs/steps)\n- Tooltip with exact values\n\n### ModelCompare.tsx\n- Multi-select model versions\n- Side-by-side metrics table\n- Overlaid loss curves\n- Select for deployment button\n\n## Pages\n\n### DatasetsPage.tsx\n- DatasetList with filters\n- Upload button  DatasetUpload modal\n- Empty state with HuggingFace import option\n\n### TrainingPage.tsx\n- Active training jobs (TrainingProgress cards)\n- Recent completed jobs list\n- \"New Training\" button  TrainingJobForm modal\n- Queue status indicator\n\n### ModelsPage.tsx\n- ModelVersionList grouped by skill\n- Stage badges (staging/production/canary)\n- Compare button for multi-select\n- Deploy button  links to deployment feature\n\n**Key Files:**\n- `app/src/features/training/` - Complete feature module\n- `app/src/app/routes.tsx` - Add /training, /datasets, /models routes\n- `app/src/shared/components/ui/FileUpload.tsx` - Reusable upload component if needed",
        "testStrategy": "Test DatasetList renders with mock data and filters work. Test DatasetUpload flow with presigned URLs (mock API). Test TrainingJobForm wizard navigation and validation. Test TrainingProgress updates via WebSocket subscription. Test LossCurveChart renders with sample metrics. Test ModelCompare displays multiple models. Use React Testing Library for component tests.",
        "priority": "high",
        "dependencies": [
          "41",
          "42"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-15T21:53:48.465Z"
      },
      {
        "id": "44",
        "title": "gRPC Infrastructure Setup (VLA Inference)",
        "description": "Set up gRPC infrastructure with Protocol Buffer definitions for VLA inference, Node.js client for robot-agent, and Python server scaffolding with health checks and connection pooling.",
        "details": "**VLA Integration Phase 3: Inference Infrastructure**\n\nEstablish low-latency gRPC communication for VLA inference between robot-agent and Python inference service.\n\n## Protocol Buffers (`protos/`)\n- **Create `protos/vla_inference.proto`**:\n  ```protobuf\n  syntax = \"proto3\";\n  package vla;\n\n  service VLAInference {\n    rpc Predict(Observation) returns (ActionChunk) {}\n    rpc StreamControl(stream Observation) returns (stream ActionChunk) {}\n    rpc GetModelInfo(Empty) returns (ModelInfo) {}\n    rpc HealthCheck(Empty) returns (HealthStatus) {}\n  }\n\n  message Observation {\n    bytes camera_image = 1;          // JPEG compressed, 224x224 or 336x336\n    repeated float joint_positions = 2;\n    repeated float joint_velocities = 3;\n    string language_instruction = 4;\n    double timestamp = 5;\n    string embodiment_tag = 6;       // e.g., \"unitree_h1\", \"so101_arm\"\n  }\n\n  message ActionChunk {\n    repeated Action actions = 1;     // 8-16 future actions\n    float inference_time_ms = 2;\n    string model_version = 3;\n    float confidence = 4;\n  }\n\n  message Action {\n    repeated float joint_commands = 1;  // Normalized [-1, 1]\n    float gripper_command = 2;          // 0=open, 1=closed\n    double timestamp = 3;\n  }\n\n  message ModelInfo {\n    string model_name = 1;\n    string model_version = 2;\n    int32 action_dim = 3;\n    int32 chunk_size = 4;\n    repeated string supported_embodiments = 5;\n  }\n\n  message HealthStatus {\n    bool ready = 1;\n    float gpu_utilization = 2;\n    float memory_utilization = 3;\n    int32 queue_depth = 4;\n  }\n\n  message Empty {}\n  ```\n\n## Robot Agent (`robot-agent/src/vla/vla-client.ts`)\n- **gRPC client implementation**:\n  - Load proto with `@grpc/proto-loader`\n  - Create client with `@grpc/grpc-js`\n  - Environment config: `VLA_INFERENCE_HOST`, `VLA_INFERENCE_PORT`\n- **Connection management**:\n  - Connection pooling (configurable pool size)\n  - Automatic reconnection with exponential backoff\n  - Health check polling every 5 seconds\n  - Connection state tracking (connecting, ready, error)\n- **Inference methods**:\n  - `predict(observation)`: Unary RPC, returns ActionChunk\n  - `startStream()`: Initialize bidirectional stream\n  - `sendObservation(obs)`: Send to stream\n  - `onActionChunk(callback)`: Receive from stream\n- **Fallback handling**:\n  - On gRPC failure, attempt REST fallback if configured\n  - Log fallback events for monitoring\n- **Metrics**:\n  - Track inference latency (P50, P95, P99)\n  - Track success/failure rates\n  - Expose via /metrics endpoint\n\n## VLA Inference (`vla-inference/`)\n- **Python gRPC server scaffold**:\n  - `vla-inference/proto/` - Proto files and generated code\n  - `vla-inference/server.py` - gRPC server setup with asyncio\n  - `vla-inference/servicer.py` - VLAInferenceServicer implementation (stub)\n- **Server configuration**:\n  - Port from `VLA_GRPC_PORT` env (default 50051)\n  - Max workers: 4\n  - Max message size: 16MB (for images)\n- **Health check implementation**:\n  - Return GPU stats from `nvidia-smi`\n  - Track request queue depth\n  - Ready = model loaded and warm\n\n## Build scripts\n- `protos/build.sh` - Generate JS and Python from proto\n- `npm run proto:build` in robot-agent\n- `make proto` in vla-inference\n\n**Key Files:**\n- `protos/vla_inference.proto` - Protocol Buffer definitions\n- `robot-agent/src/vla/vla-client.ts` - gRPC client with connection management\n- `robot-agent/src/vla/vla-client.test.ts` - Client tests with mock server\n- `vla-inference/server.py` - Python gRPC server scaffold\n- `vla-inference/servicer.py` - Inference servicer stub\n- `vla-inference/proto/` - Generated Python code",
        "testStrategy": "Test proto compilation for Node.js and Python succeeds. Test gRPC client connects to server. Test health check returns valid response. Test reconnection after server restart. Test fallback to REST on gRPC failure. Test streaming RPC with multiple observations. Test connection pool reuses connections. Use grpc-mock for unit tests.",
        "priority": "high",
        "dependencies": [
          "37"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-13T22:26:21.633Z"
      },
      {
        "id": "45",
        "title": "VLA Inference Service - Model Agnostic (VLA Inference)",
        "description": "Build Python gRPC server with model-agnostic architecture supporting 0.6, OpenVLA, and future GR00T models, with vLLM batching optimized for cloud GPU (H100).",
        "details": "**VLA Integration Phase 3: Inference Infrastructure**\n\nImplement production-ready VLA inference service with pluggable model backends.\n\n## VLA Inference (`vla-inference/`)\n- **Project structure**:\n  ```\n  vla-inference/\n   proto/\n      vla_inference_pb2.py (generated)\n   models/\n      __init__.py\n      base.py          # Abstract model interface\n      pi0.py           # 0.6 implementation\n      openvla.py       # OpenVLA implementation\n      groot.py         # GR00T stub\n   inference_server.py  # gRPC server entry point\n   servicer.py          # VLAInferenceServicer\n   config.py            # Configuration management\n   metrics.py           # Prometheus metrics\n   Dockerfile\n   requirements.txt\n   tests/\n  ```\n\n## Abstract Model Interface (`models/base.py`)\n```python\nfrom abc import ABC, abstractmethod\n\nclass VLAModel(ABC):\n    @abstractmethod\n    def load(self, checkpoint_path: str, device: str = \"cuda\") -> None:\n        \"\"\"Load model weights to GPU.\"\"\"\n        pass\n\n    @abstractmethod\n    def predict(self, observation: Observation) -> ActionChunk:\n        \"\"\"Single inference, returns action chunk.\"\"\"\n        pass\n\n    @abstractmethod\n    def predict_batch(self, observations: list[Observation]) -> list[ActionChunk]:\n        \"\"\"Batched inference for throughput.\"\"\"\n        pass\n\n    @abstractmethod\n    def unload(self) -> None:\n        \"\"\"Release GPU memory.\"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def model_info(self) -> ModelInfo:\n        \"\"\"Return model metadata.\"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def chunk_size(self) -> int:\n        \"\"\"Number of actions per chunk.\"\"\"\n        pass\n```\n\n## 0.6 Implementation (`models/pi0.py`)\n- Use OpenPI library for 0.6 model\n- Load from HuggingFace or local checkpoint\n- Image preprocessing: resize, normalize\n- Action denormalization per embodiment\n- Chunk size: 16 actions at 50Hz = 320ms lookahead\n- Support LoRA adapter loading for fine-tuned models\n\n## OpenVLA Implementation (`models/openvla.py`)\n- Load OpenVLA 7B model\n- Transformers library integration\n- 8-bit quantization option for memory\n- Chunk size: 8 actions\n- Fallback when 0 unavailable\n\n## Inference Servicer (`servicer.py`)\n- **Model management**:\n  - Load model on startup based on config\n  - Support hot-swap via config reload\n  - Track active model version\n- **Predict implementation**:\n  - Deserialize observation from proto\n  - Preprocess image (decode JPEG, resize, normalize)\n  - Run model inference\n  - Serialize ActionChunk to proto\n  - Track inference latency\n- **Batching with vLLM** (optional):\n  - Queue incoming requests\n  - Batch when queue full or timeout (10ms)\n  - Improves throughput 2-4x\n\n## GPU Management\n- **Memory optimization**:\n  - Model fits in 40GB (H100 has 80GB)\n  - Reserve 20GB for batch inference\n  - Clear cache between model swaps\n- **Batch size auto-tuning**:\n  - Start with batch_size=1\n  - Increase if latency allows\n  - Target: <100ms P99 latency\n- **OOM handling**:\n  - Catch CUDA OOM\n  - Reduce batch size\n  - Log warning\n\n## Health & Metrics\n- Prometheus metrics:\n  - `vla_inference_latency_seconds` histogram\n  - `vla_inference_requests_total` counter\n  - `vla_gpu_utilization` gauge\n  - `vla_gpu_memory_used_bytes` gauge\n- Health endpoint:\n  - Model loaded and warmed up\n  - GPU available and healthy\n  - Queue depth reasonable (<100)\n\n## Dockerfile\n- Base: `nvcr.io/nvidia/pytorch:24.01-py3`\n- Install dependencies\n- Copy model configs\n- Entrypoint: `python inference_server.py`\n- GPU runtime required\n\n**Key Files:**\n- `vla-inference/models/base.py` - Abstract VLAModel interface\n- `vla-inference/models/pi0.py` - 0.6 implementation\n- `vla-inference/models/openvla.py` - OpenVLA implementation\n- `vla-inference/servicer.py` - gRPC servicer with batching\n- `vla-inference/inference_server.py` - Server entry point\n- `vla-inference/Dockerfile` - GPU-enabled container\n- `vla-inference/requirements.txt` - Python dependencies",
        "testStrategy": "Test model loading succeeds on GPU. Test inference returns valid action chunk dimensions. Test batch inference throughput (>10 req/s on H100). Test model hot-swap works without restart. Test GPU memory stays under limit during inference. Test health check reflects actual readiness. Test graceful handling of malformed observations. Use pytest with GPU fixtures.",
        "priority": "high",
        "dependencies": [
          "44"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-14T00:30:54.821Z"
      },
      {
        "id": "46",
        "title": "Action Buffer on Robot Agent (VLA Inference)",
        "description": "Implement client-side action buffer with interpolation for network latency tolerance, predictive action selection, safety fallback on buffer underrun, and seamless cloud/edge switching.",
        "details": "**VLA Integration Phase 3: Inference Infrastructure**\n\nCreate robust action buffering to maintain smooth robot control despite network latency.\n\n## Robot Agent (`robot-agent/src/vla/action-buffer.ts`)\n- **Circular buffer implementation**:\n  - Fixed capacity: 16 actions (320ms at 50Hz)\n  - Thread-safe with mutex (use `async-mutex`)\n  - Methods: `push(actions[])`, `pop()`, `peek()`, `clear()`\n  - Track buffer level: empty, low (under 25%), normal, full\n- **Buffer monitoring**:\n  - Emit events: `buffer:low`, `buffer:empty`, `buffer:full`\n  - Log buffer level periodically (every 1s)\n  - Metrics: buffer_level, underrun_count, refill_count\n- **Prefetch logic**:\n  - Request new chunk when buffer below 50%\n  - Track in-flight requests to avoid duplicates\n  - Measure RTT and adjust prefetch threshold\n\n## Robot Agent (`robot-agent/src/vla/action-interpolator.ts`)\n- **Interpolation methods**:\n  - Linear: simple lerp between actions\n  - Cubic: smoother acceleration curves\n  - Configurable via `INTERPOLATION_METHOD` env\n- **Timestamp-based selection**:\n  - Actions have timestamps from inference\n  - Select action closest to current time\n  - Handle clock drift between server and robot\n- **Latency compensation**:\n  - Measure network RTT\n  - Offset action selection by RTT estimate\n  - Smooth RTT estimate with exponential moving average\n\n## Robot Agent (`robot-agent/src/vla/vla-controller.ts`)\n- **High-level controller**:\n  - Initialize VLAClient and ActionBuffer\n  - Main control loop at 50Hz (20ms period)\n  - On each tick:\n    1. Pop action from buffer\n    2. If buffer low, request new chunk (async)\n    3. Interpolate if needed\n    4. Apply action to robot\n    5. Check safety constraints\n  - Handle mode switching (VLA active, paused, stopped)\n- **Safety fallback**:\n  - On buffer underrun: hold last position\n  - On extended underrun (>500ms): safe retract\n  - On network loss: switch to local safety controller\n  - Log all fallback events\n- **Cloud/edge switching**:\n  - Primary endpoint: cloud GPU\n  - Fallback endpoint: edge device (if available)\n  - Automatic failover on cloud timeout\n  - Maintain action continuity during switch\n\n## Integration (`robot-agent/src/robot/state.ts`)\n- Add VLA control mode to RobotStateManager\n- Methods:\n  - `startVLAControl(instruction)`: Initialize VLA session\n  - `stopVLAControl()`: Graceful stop, drain buffer\n  - `getVLAStatus()`: Buffer level, inference latency, mode\n- Coordinate with existing CommandExecutor\n\n## Integration (`robot-agent/src/robot/CommandExecutor.ts`)\n- Add `executeVLAAction(action)` method\n- Map VLA action format to robot commands\n- Validate action within safety limits before execution\n\n**Key Files:**\n- `robot-agent/src/vla/action-buffer.ts` - Circular buffer implementation\n- `robot-agent/src/vla/action-interpolator.ts` - Smooth interpolation\n- `robot-agent/src/vla/vla-controller.ts` - High-level VLA control\n- `robot-agent/src/robot/state.ts` - Add VLA mode (update existing)\n- `robot-agent/src/robot/CommandExecutor.ts` - Add VLA action execution (update existing)",
        "testStrategy": "Test buffer fill and drain at 50Hz rate. Test prefetch triggers at 50% level. Test interpolation produces smooth motion. Test underrun triggers safety fallback within 50ms. Test cloud/edge switching maintains under 100ms gap. Test position hold on buffer empty. Test RTT estimation converges to actual latency. Use fake timers for deterministic tests.",
        "priority": "high",
        "dependencies": [
          "44",
          "45"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-15T22:25:39.743Z"
      },
      {
        "id": "47",
        "title": "Model Deployment Pipeline (VLA Fleet)",
        "description": "Implement skill deployment to robot fleets with canary rollout (5%  20%  50%  100%), automatic rollback on error thresholds, and WebSocket-based deployment status tracking.",
        "details": "**VLA Integration Phase 4: Fleet Deployment**\n\nBuild production deployment pipeline for rolling out trained models to robot fleets.\n\n## Server (`server/src/services/DeploymentService.ts`)\n- **Deployment creation**:\n  - `createDeployment(modelVersionId, config)`: Initialize deployment\n    - Validate model version exists and has artifacts\n    - Validate target robots are compatible (robotType match)\n    - Create Deployment record with status=pending\n    - Return deployment ID\n- **Canary rollout**:\n  - `startCanary(deploymentId)`: Begin staged rollout\n    - Stage 1: 5% of target robots (minimum 1)\n    - Stage 2: 20% after stage 1 success (24h default)\n    - Stage 3: 50% after stage 2 success\n    - Stage 4: 100% (full production)\n  - Configurable stage durations and percentages\n  - Automatic progression if metrics pass thresholds\n- **Robot selection for canary**:\n  - Random selection from eligible robots\n  - Prefer robots with lower utilization\n  - Exclude robots with recent failures\n  - Track deployed vs pending robots\n- **Rollback thresholds**:\n  - Error rate > 5% triggers rollback\n  - Latency P99 > 500ms triggers rollback\n  - Task failure rate > 10% triggers rollback\n  - Manual rollback always available\n- **Rollback execution**:\n  - `rollback(deploymentId)`: Revert to previous model\n    - Mark deployment as rolling_back\n    - Signal robots to reload previous model\n    - Track rollback progress\n    - Mark complete when all robots reverted\n- **Promotion**:\n  - `promoteToProduction(deploymentId)`: Skip remaining canary\n  - Requires explicit confirmation\n  - Updates model version stage in MLflow\n\n## Server (`server/src/routes/deployments.routes.ts`)\n- `POST /api/deployments` - Create deployment\n- `GET /api/deployments` - List deployments with filters\n- `GET /api/deployments/:id` - Get deployment status\n- `POST /api/deployments/:id/start` - Start canary rollout\n- `POST /api/deployments/:id/promote` - Promote to next stage\n- `POST /api/deployments/:id/rollback` - Trigger rollback\n- `GET /api/deployments/:id/metrics` - Get deployment metrics\n\n## Server (`server/src/services/DeploymentMetricsService.ts`)\n- **Metric collection**:\n  - Aggregate error rates from deployed robots\n  - Calculate latency percentiles\n  - Track task success/failure rates\n- **Threshold monitoring**:\n  - Check thresholds every 60 seconds\n  - Trigger automatic rollback if exceeded\n  - Log threshold breaches\n\n## WebSocket events\n- `deployment:created` - New deployment\n- `deployment:stage:started` - Canary stage began\n- `deployment:stage:completed` - Canary stage passed\n- `deployment:robot:deployed` - Individual robot updated\n- `deployment:rollback:started` - Rollback triggered\n- `deployment:completed` - Full production deployment\n- `deployment:failed` - Deployment failed\n\n## Robot Agent integration\n- New endpoint: `POST /vla/model/switch`\n  - Body: `{ modelVersion, artifactUri }`\n  - Download model from RustFS\n  - Hot-swap in inference client\n  - Report success/failure to server\n\n**Key Files:**\n- `server/src/services/DeploymentService.ts` - Deployment orchestration\n- `server/src/services/DeploymentMetricsService.ts` - Metric aggregation\n- `server/src/routes/deployments.routes.ts` - REST API endpoints\n- `server/prisma/schema.prisma` - Deployment model (already added in Task 37)\n- `server/src/websocket/index.ts` - Add deployment events (update existing)",
        "testStrategy": "Test canary stage progression (5%  20%  50%  100%). Test automatic rollback when error rate exceeds threshold. Test manual rollback at any stage. Test robot selection distributes evenly. Test WebSocket events fire for all lifecycle stages. Test promotion skips remaining stages. Test concurrent deployments are prevented for same skill.",
        "priority": "high",
        "dependencies": [
          "40",
          "45"
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": "48",
        "title": "Skill Library Management (VLA Fleet)",
        "description": "Implement skill abstraction layer with CRUD operations, Zod-based parameter schemas, precondition/postcondition definitions, embodiment compatibility mapping, and skill chaining for complex tasks.",
        "details": "**VLA Integration Phase 4: Fleet Deployment**\n\nBuild skill library for organizing and executing VLA-trained behaviors.\n\n## Server (`server/src/types/skill.types.ts`)\n- **SkillDefinition types**:\n  ```typescript\n  interface SkillDefinition {\n    id: string;\n    name: string;\n    version: string;\n    description: string;\n    parametersSchema: ZodSchema;  // JSON Schema format for storage\n    defaultParameters: Record[string, unknown];\n    preconditions: Condition[];\n    postconditions: Condition[];\n    compatibleRobotTypes: string[];\n    requiredCapabilities: string[];\n    timeout: number;  // seconds\n    maxRetries: number;\n    status: 'draft' | 'published' | 'deprecated' | 'archived';\n    linkedModelVersionId?: string;\n  }\n\n  interface Condition {\n    type: 'sensor' | 'state' | 'custom';\n    name: string;  // e.g., \"gripper_empty\", \"object_visible\"\n    check: string;  // Expression or function name\n    params?: Record[string, unknown];\n  }\n\n  interface SkillChain {\n    id: string;\n    name: string;\n    skills: SkillChainStep[];\n  }\n\n  interface SkillChainStep {\n    skillId: string;\n    parameters: Record[string, unknown];\n    inputMapping?: Record[string, string];  // Map previous output to input\n    onFailure: 'abort' | 'skip' | 'retry';\n  }\n  ```\n\n## Server (`server/src/services/SkillLibraryService.ts`)\n- **Skill CRUD**:\n  - `create(dto)`: Create skill with draft status\n  - `get(id)`: Get skill with relations\n  - `list(query)`: Filter by robotType, status, capability\n  - `update(id, dto)`: Update and bump version\n  - `publish(id)`: Change status to published\n  - `deprecate(id)`: Mark as deprecated\n  - `archive(id)`: Mark as archived (not deleted)\n- **Parameter validation**:\n  - `validateParameters(skillId, params)`: Zod validation\n  - Return detailed error messages\n- **Condition checking**:\n  - `checkPreconditions(skillId, robotState)`: Verify robot ready\n  - `checkPostconditions(skillId, robotState)`: Verify success\n  - Support custom condition functions\n- **Compatibility checking**:\n  - `getCompatibleSkills(robotTypeId)`: Filter by robot type\n  - `checkCapabilities(skillId, robotCapabilities)`: Verify robot has required capabilities\n- **Skill chaining**:\n  - `createChain(dto)`: Create skill sequence\n  - `executeChain(chainId, robotId)`: Run skills in order\n  - Handle input/output mapping between steps\n  - Support failure handling strategies\n\n## Server (`server/src/routes/skills.routes.ts`)\n- `POST /api/skills` - Create skill\n- `GET /api/skills` - List skills with filters\n- `GET /api/skills/:id` - Get skill details\n- `PUT /api/skills/:id` - Update skill\n- `POST /api/skills/:id/publish` - Publish skill\n- `POST /api/skills/:id/deprecate` - Deprecate skill\n- `POST /api/skills/:id/archive` - Archive skill\n- `POST /api/skills/:id/validate` - Validate parameters\n- `GET /api/skills/:id/compatible-robots` - Get compatible robots\n- `POST /api/skill-chains` - Create chain\n- `GET /api/skill-chains` - List chains\n- `POST /api/skill-chains/:id/execute` - Execute chain\n\n## Server (`server/src/services/SkillExecutionService.ts`)\n- **Skill execution**:\n  - `execute(skillId, robotId, parameters)`: Run single skill\n    - Validate parameters\n    - Check preconditions\n    - Send to robot via VLA controller\n    - Monitor progress\n    - Check postconditions\n    - Return result\n- **Chain execution**:\n  - Execute skills sequentially\n  - Handle parameter passing\n  - Handle failures per step config\n\n**Key Files:**\n- `server/src/types/skill.types.ts` - Skill and chain type definitions\n- `server/src/services/SkillLibraryService.ts` - Skill CRUD and validation\n- `server/src/services/SkillExecutionService.ts` - Skill and chain execution\n- `server/src/routes/skills.routes.ts` - REST API endpoints",
        "testStrategy": "Test skill creation with valid schema. Test parameter validation rejects invalid values. Test precondition checking (gripper_empty, object_visible). Test postcondition verification. Test robot type compatibility filtering. Test skill versioning increments on update. Test chain execution runs skills in order. Test chain failure handling (abort, skip, retry).",
        "priority": "medium",
        "dependencies": [
          "37",
          "47"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-15T23:25:35.537Z"
      },
      {
        "id": "49",
        "title": "Deployment Frontend (VLA Fleet)",
        "description": "Build React feature module for fleet deployment with model version browser, canary configuration wizard, real-time deployment progress tracking, rollback controls, and skill library browser.",
        "details": "**VLA Integration Phase 4: Fleet Deployment**\n\nCreate deployment management UI for fleet operators.\n\n## App (`app/src/features/deployment/`)\n- **Feature structure**:\n  ```\n  deployment/\n   types/deployment.types.ts\n   api/deploymentApi.ts\n   store/deploymentStore.ts\n   hooks/\n      useDeployments.ts\n      useSkills.ts\n      useDeploymentMetrics.ts\n   components/\n      ModelBrowser.tsx\n      ModelVersionCard.tsx\n      CanaryConfig.tsx\n      DeploymentStatus.tsx\n      DeploymentProgress.tsx\n      RobotDeploymentList.tsx\n      RollbackConfirmation.tsx\n      SkillBrowser.tsx\n      SkillCard.tsx\n      SkillEditor.tsx\n      RobotSelector.tsx\n   pages/\n       DeploymentsPage.tsx\n       DeploymentDetailPage.tsx\n       SkillsPage.tsx\n  ```\n\n## Types (`deployment.types.ts`)\n- Mirror server types: Deployment, DeploymentStage, SkillDefinition, SkillChain\n- Define UI types: CanaryStageConfig, RollbackThresholds, DeploymentFilters\n\n## Components\n\n### ModelBrowser.tsx\n- List model versions grouped by skill\n- Filter by skill, status (staging/production/canary)\n- Metrics preview (accuracy, latency)\n- Select for deployment action\n\n### CanaryConfig.tsx\n- Stage configuration wizard:\n  1. Select model version\n  2. Configure stages (%, duration per stage)\n  3. Set rollback thresholds (error rate, latency)\n  4. Select target robots (type, zone)\n  5. Review and confirm\n- Preset templates: \"Quick canary\", \"Conservative\", \"Custom\"\n- Estimated timeline display\n\n### DeploymentStatus.tsx\n- Current stage indicator (progress steps)\n- Stage metrics (error rate, latency percentiles)\n- Time in stage and time remaining\n- Promote and rollback buttons\n- Status badge (deploying, canary, production, failed)\n\n### DeploymentProgress.tsx\n- Per-robot deployment status grid\n- Success/pending/failed badges\n- Click to see robot details\n- Retry failed robots action\n\n### RobotDeploymentList.tsx\n- Table of robots in deployment\n- Columns: robot name, status, deployed at, error message\n- Sort by status, time\n- Bulk actions\n\n### RollbackConfirmation.tsx\n- Modal with warning\n- Show current vs previous version\n- Affected robot count\n- Confirm/cancel buttons\n\n### SkillBrowser.tsx\n- Grid of skill cards\n- Filter by robot type, status\n- Version badges\n- Link to model versions\n\n### SkillEditor.tsx\n- Form for skill metadata\n- JSON editor for parameter schema\n- Precondition/postcondition builder\n- Robot compatibility selector\n- Publish/deprecate actions\n\n## Pages\n\n### DeploymentsPage.tsx\n- List of active and recent deployments\n- Filter by status, skill, date\n- \"New Deployment\" button  CanaryConfig\n- Summary stats (active, completed, failed)\n\n### DeploymentDetailPage.tsx\n- Full deployment status\n- Live metrics charts\n- Robot deployment list\n- Action buttons (promote, rollback)\n- Timeline of events\n\n### SkillsPage.tsx\n- SkillBrowser with filters\n- \"Create Skill\" button  SkillEditor\n- Skill chain management\n\n**Key Files:**\n- `app/src/features/deployment/` - Complete feature module\n- `app/src/app/routes.tsx` - Add /deployments, /skills routes",
        "testStrategy": "Test ModelBrowser renders versions grouped by skill. Test CanaryConfig wizard validation and submission. Test DeploymentProgress updates via WebSocket. Test rollback confirmation flow. Test SkillBrowser filters by robot type. Test SkillEditor form validation. Use React Testing Library with mock API.",
        "priority": "medium",
        "dependencies": [
          "47",
          "48"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-16T00:32:52.794Z"
      },
      {
        "id": "50",
        "title": "Enhanced VLA Safety Monitoring (VLA Safety)",
        "description": "Extend robot safety monitoring for VLA control with action validation, rate limiting for sudden movements, workspace boundary enforcement, network watchdog (50-100ms timeout), and graceful degradation.",
        "details": "**VLA Integration Phase 5: Safety & Simulation**\n\nImplement safety-critical extensions for VLA-based robot control.\n\n## Robot Agent (`robot-agent/src/safety/vla-safety.ts`)\n- **Action validation**:\n  - `validateAction(action, limits)`: Check before execution\n    - Joint position within limits\n    - Joint velocity within limits\n    - Joint acceleration within limits (derived)\n    - Gripper command valid (0-1)\n  - Return: `{ valid: boolean, violations: string[] }`\n  - Reject invalid actions with logging\n- **Rate limiting**:\n  - Track action derivatives (velocity, acceleration)\n  - `maxJerk` limit: prevent jarring movements\n  - `maxDirectionChange`: limit sudden reversals\n  - Smooth trajectory if rate exceeded\n- **Workspace boundaries**:\n  - Define workspace envelope (box or convex hull)\n  - `checkWorkspaceBounds(position)`: Is position inside?\n  - `projectToWorkspace(position)`: Clamp to boundary\n  - Gradual slowdown near boundaries (last 10cm)\n  - Hard stop at boundary\n- **Integration with SafetyMonitor**:\n  - Add VLA safety checks to monitoring tick\n  - Priority: VLA safety is lower priority than E-stop (E-stop always wins)\n\n## Robot Agent (`robot-agent/src/safety/network-watchdog.ts`)\n- **Network watchdog**:\n  - Configurable timeout: 50-100ms default\n  - Track last successful inference response\n  - On timeout:\n    1. Log warning\n    2. Continue with buffered actions if available\n    3. Trigger protective stop if buffer empty\n  - On extended loss (>500ms):\n    1. Log error\n    2. Execute safe retract sequence\n    3. Notify server of degraded mode\n- **Safe retract sequence**:\n  - Pre-defined per robot type\n  - Move to neutral position slowly\n  - Open gripper if holding object\n  - Come to controlled stop\n  - Enter safe mode\n\n## Robot Agent (`robot-agent/src/safety/graceful-degradation.ts`)\n- **Degradation modes**:\n  - `normal`: Full VLA control\n  - `reduced`: Lower speed limits, more conservative\n  - `fallback`: Local safety controller only\n  - `stopped`: Position hold, await operator\n- **Mode transitions**:\n  - `normal  reduced`: Intermittent network issues\n  - `reduced  fallback`: Sustained network issues\n  - `fallback  stopped`: Safety event or operator request\n  - Recovery: `stopped  fallback  reduced  normal`\n- **Operator alerts**:\n  - Emit alerts on mode transitions\n  - Require acknowledgment to resume normal mode\n- **Resume procedure**:\n  - Connection restored\n  - Buffer refilled\n  - Operator confirmation (if required)\n  - Gradual speed ramp-up\n\n## Integration\n- Update `SafetyMonitor.ts`:\n  - Add `vlaSafetyCheck()` to monitoring tick\n  - Add `networkWatchdog` component\n  - Add `degradationMode` state\n- Update `action-buffer.ts`:\n  - Report buffer status to safety monitor\n  - Trigger degradation on underrun\n\n## Compliance logging\n- Log all safety interventions to ComplianceLogService\n- Include: action attempted, violation type, corrective action\n- Retention per existing retention policy\n\n**Key Files:**\n- `robot-agent/src/safety/vla-safety.ts` - VLA-specific safety checks\n- `robot-agent/src/safety/network-watchdog.ts` - Network timeout handling\n- `robot-agent/src/safety/graceful-degradation.ts` - Degradation mode management\n- `robot-agent/src/safety/SafetyMonitor.ts` - Integrate VLA safety (update existing)\n- `robot-agent/src/vla/action-buffer.ts` - Safety integration (update existing)",
        "testStrategy": "Test action validation rejects out-of-limits actions. Test rate limiting smooths sudden movements. Test workspace boundary stops robot at edge. Test watchdog triggers at timeout threshold (10ms accuracy). Test safe retract executes within 2 seconds. Test graceful degradation mode transitions. Test compliance logging captures all interventions. Test recovery sequence works end-to-end.",
        "priority": "high",
        "dependencies": [
          "30",
          "46"
        ],
        "status": "deferred",
        "subtasks": [],
        "updatedAt": "2026-01-15T23:05:32.457Z"
      },
      {
        "id": "51",
        "title": "Embodiment Configuration System (VLA Simulation)",
        "description": "Implement multi-robot embodiment support with YAML configuration files, action normalization per embodiment, camera configuration, and joint mapping for H1 humanoid and SO101 arm robots.",
        "details": "**VLA Integration Phase 5: Safety & Simulation**\n\nCreate flexible embodiment configuration for supporting multiple robot types.\n\n## Robot Agent (`robot-agent/src/embodiment/configs/`)\n- **H1 humanoid config** (`h1.yaml`):\n  ```yaml\n  embodiment_tag: unitree_h1\n  manufacturer: Unitree\n  model: H1\n\n  action:\n    dim: 7  # 6 arm joints + gripper\n    normalization:\n      mean: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5]\n      std: [0.3, 0.3, 0.3, 0.2, 0.2, 0.2, 0.3]\n\n  proprioception:\n    dim: 14  # positions + velocities\n    joint_names:\n      - left_shoulder_pitch\n      - left_shoulder_roll\n      - left_elbow\n      - left_wrist_roll\n      - left_wrist_pitch\n      - left_wrist_yaw\n      - left_gripper\n\n  cameras:\n    - name: head_camera\n      resolution: [224, 224]\n      fov: 90\n      position: [0, 0, 0.5]  # relative to base\n    - name: wrist_camera\n      resolution: [224, 224]\n      fov: 60\n      position: [0, 0, 0]  # on gripper\n\n  limits:\n    position:  # [min, max] per joint\n      - [-3.14, 3.14]\n      - [-1.57, 1.57]\n      # ... etc\n    velocity: [2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 1.0]\n    torque: [40, 40, 30, 20, 20, 20, 10]\n\n  safety:\n    max_speed: 0.25  # m/s in manual mode\n    workspace:\n      type: box\n      min: [-0.5, -0.5, 0.1]\n      max: [0.5, 0.5, 1.0]\n  ```\n- **SO101 arm config** (`so101.yaml`): Similar structure, different dimensions\n\n## Robot Agent (`robot-agent/src/embodiment/embodiment-loader.ts`)\n- **Config loading**:\n  - `loadEmbodiment(tag)`: Load YAML by embodiment tag\n  - `listEmbodiments()`: Return available embodiments\n  - `getDefault()`: Return default embodiment\n  - Validate config structure with Zod\n- **Hot-reload**:\n  - Watch config directory for changes\n  - Reload on file modification\n  - Emit `embodiment:reloaded` event\n  - Validate before applying\n\n## Robot Agent (`robot-agent/src/embodiment/normalizer.ts`)\n- **Action normalization**:\n  - `normalize(rawAction, embodiment)`: Raw  [-1, 1]\n    - `normalized = (raw - mean) / std`\n  - `denormalize(normalizedAction, embodiment)`: [-1, 1]  Raw\n    - `raw = normalized * std + mean`\n- **Per-embodiment stats**:\n  - Load from config (mean, std)\n  - Override from dataset stats if available\n\n## Robot Agent (`robot-agent/src/embodiment/camera-config.ts`)\n- **Camera configuration**:\n  - Resolution per camera\n  - FOV and position\n  - Image preprocessing pipeline\n    - Resize to model input size\n    - Normalize pixel values\n    - Stack multiple cameras if required\n\n## Robot Agent (`robot-agent/src/embodiment/joint-mapper.ts`)\n- **Joint mapping**:\n  - Map VLA action indices to robot joint names\n  - Handle different DOF counts between models\n  - Zero-fill or ignore extra dimensions\n- **Validation**:\n  - Check action dim matches embodiment\n  - Log warnings for dimension mismatch\n\n## Server (`server/src/services/EmbodimentService.ts`)\n- **Server-side registry**:\n  - Store embodiment configs in database\n  - API for listing and retrieving\n  - Sync with robot-agent configs\n- **Robot type mapping**:\n  - Link Robot records to embodiment tags\n  - Auto-detect based on robot model\n\n## Server (`server/src/routes/embodiments.routes.ts`)\n- `GET /api/embodiments` - List available embodiments\n- `GET /api/embodiments/:tag` - Get embodiment config\n- `POST /api/embodiments` - Create/update embodiment\n\n**Key Files:**\n- `robot-agent/src/embodiment/configs/h1.yaml` - H1 humanoid config\n- `robot-agent/src/embodiment/configs/so101.yaml` - SO101 arm config\n- `robot-agent/src/embodiment/embodiment-loader.ts` - Config loading\n- `robot-agent/src/embodiment/normalizer.ts` - Action normalization\n- `robot-agent/src/embodiment/camera-config.ts` - Camera setup\n- `robot-agent/src/embodiment/joint-mapper.ts` - Joint mapping\n- `server/src/services/EmbodimentService.ts` - Server-side registry\n- `server/src/routes/embodiments.routes.ts` - REST API",
        "testStrategy": "Test config loading from YAML files. Test validation rejects malformed configs. Test normalization/denormalization is reversible. Test joint mapping for H1 (7 DOF) and SO101 (6 DOF). Test camera config produces correct image dimensions. Test hot-reload updates running embodiment. Test auto-detection assigns correct embodiment to robot.",
        "priority": "medium",
        "dependencies": [
          "37",
          "46"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-17T01:26:29.819Z"
      },
      {
        "id": "52",
        "title": "ROS 2 Bridge - DEFERRED (VLA Hardware)",
        "description": "[DEFERRED] ROS 2 integration for real hardware using rclnodejs, to be implemented when transitioning from simulation to physical robots.",
        "details": "**VLA Integration Phase 6: Real Hardware (DEFERRED)**\n\nThis task is deferred until physical robot deployment is required. The current system uses simulation.\n\n## Planned Implementation\n\n### Robot Agent (`robot-agent/src/ros2/ros2-bridge.ts`)\n- **rclnodejs initialization**:\n  - Create ROS 2 node: `vla_control_node`\n  - Lifecycle management (configure, activate, deactivate)\n  - Parameter configuration via ROS 2 parameters\n- **Executor setup**:\n  - Multi-threaded executor\n  - Spin in background thread\n  - Graceful shutdown handling\n\n### Robot Agent (`robot-agent/src/ros2/subscriptions.ts`)\n- **Sensor subscriptions**:\n  - Camera: `sensor_msgs/CompressedImage` on `/camera/image_compressed`\n  - Joint states: `sensor_msgs/JointState` on `/joint_states`\n  - Force/torque: `geometry_msgs/WrenchStamped` on `/force_torque`\n- **Data conversion**:\n  - ROS message  VLA Observation format\n  - Handle timestamp synchronization\n  - Buffer recent messages for observation assembly\n\n### Robot Agent (`robot-agent/src/ros2/actions.ts`)\n- **Trajectory execution**:\n  - Action client for `control_msgs/FollowJointTrajectory`\n  - Convert VLA ActionChunk  JointTrajectory message\n  - Handle action feedback and result\n- **Gripper control**:\n  - Service client or action for gripper\n  - Map VLA gripper command to robot-specific interface\n\n### Prerequisites\n- ROS 2 Humble or Jazzy installed\n- rclnodejs package: `npm install rclnodejs`\n- Robot-specific ROS 2 drivers (from robot manufacturer)\n- Network configuration for ROS 2 DDS\n\n**Key Files (Future):**\n- `robot-agent/src/ros2/ros2-bridge.ts` - ROS 2 node lifecycle\n- `robot-agent/src/ros2/subscriptions.ts` - Sensor data handling\n- `robot-agent/src/ros2/actions.ts` - Trajectory execution\n- `robot-agent/package.json` - Add rclnodejs dependency\n\n**Note:** Implementation will begin when physical hardware is available and tested.",
        "testStrategy": "N/A - Task is deferred. When implemented: Test ROS 2 node lifecycle (configure  activate  deactivate). Test sensor subscription receives data. Test trajectory action execution completes. Test VLA  ROS data conversion accuracy. Test error handling for ROS 2 communication failures.",
        "priority": "low",
        "dependencies": [
          "46",
          "50"
        ],
        "status": "deferred",
        "subtasks": []
      },
      {
        "id": "53",
        "title": "Advanced Data Quality Validation Pipeline (VLA Data)",
        "description": "Implement trajectory quality metrics including RMS jerk, action consistency, anomaly detection, and OOD detection framework for training data validation.",
        "details": "**VLA Data Strategy Phase 1: Quality Metrics (13 SP)**\n\nImplement comprehensive trajectory quality metrics beyond basic scoring.\n\n## Server (`server/src/services/DataQualityService.ts`)\n- **Trajectory smoothness metrics:**\n  - `computeRMSJerk(trajectory)`: RMS of dp/dt for joint trajectories\n  - `computeLDLJ(trajectory)`: Logarithmic Dimensionless Jerk (normalized, noise-resistant)\n  - `computePositionInstability(trajectory)`: TCP position variations ||p_t - p_{t-1}||\n- **Action consistency metrics:**\n  - `computePathLengthVariance(demonstrations)`: Variance across demos of same task\n  - `computeDTWDistance(traj1, traj2)`: Dynamic Time Warping distance\n  - `computeEffortMetric(trajectory)`: Integrated torque over trajectory\n- **Anomaly detection:**\n  - `detectStatisticalOutliers(dataset)`: Z-score and IQR-based detection\n  - `detectEnvelopeViolations(trajectory, bounds)`: Trajectory envelope checking\n  - `detectVelocitySpikes(trajectory, threshold)`: Sudden velocity/acceleration detection\n- **OOD detection framework:**\n  - Interface for cVAE reconstruction error (placeholder for ML model)\n  - `flagHighReconstructionError(observations, threshold)`: Flag OOD samples\n  - Human review queue for flagged samples\n- **Quality scoring integration:**\n  - Extend DatasetService.computeQualityScore() with new metrics\n  - Weights: smoothness (30), consistency (30), anomaly-free (20), completeness (20)\n  - Store per-trajectory metrics in database\n\n## Server (`server/src/types/data-quality.types.ts`)\n```typescript\ninterface TrajectoryMetrics {\n  rmsJerk: number;\n  ldlj: number;\n  positionInstability: number;\n  pathLength: number;\n  effort: number;\n  hasAnomalies: boolean;\n  anomalyTypes: string[];\n}\n\ninterface DatasetQualityReport {\n  datasetId: string;\n  overallScore: number;\n  smoothnessScore: number;\n  consistencyScore: number;\n  anomalyScore: number;\n  completenessScore: number;\n  trajectoryCount: number;\n  flaggedTrajectoryCount: number;\n  metrics: TrajectoryMetrics[];\n}\n```\n\n## Server (`server/src/routes/datasets.routes.ts`)\n- `GET /api/datasets/:id/quality` - Detailed quality breakdown\n- `GET /api/datasets/:id/trajectories/:idx/metrics` - Per-trajectory metrics\n- `POST /api/datasets/:id/validate-advanced` - Trigger advanced validation job\n- `GET /api/datasets/:id/flagged` - List flagged trajectories for review\n- `POST /api/datasets/:id/trajectories/:idx/unflag` - Mark as reviewed\n\n**Key Files:**\n- `server/src/services/DataQualityService.ts` - Core quality computation\n- `server/src/types/data-quality.types.ts` - Type definitions\n- Update `server/src/services/DatasetService.ts` - Integration\n- Update `server/src/routes/datasets.routes.ts` - New endpoints",
        "testStrategy": "Test RMS jerk computation against known smooth vs jerky trajectories. Test DTW distance is symmetric and zero for identical trajectories. Test anomaly detection flags obvious outliers (>3 sigma). Test quality score weights sum to 100. Test flagged trajectories appear in review queue. Test validation job completes and updates dataset record.",
        "priority": "high",
        "dependencies": [
          "41"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-17T01:28:54.938Z"
      },
      {
        "id": "54",
        "title": "Teleoperation Data Collection Infrastructure (VLA Data)",
        "description": "Implement teleoperation session management for VR (Quest/Vision Pro) and bilateral (ALOHA-style) data collection with LeRobot export.",
        "details": "**VLA Data Strategy Phase 1: Data Collection (21 SP)**\n\nImplement teleoperation infrastructure for high-quality demonstration collection.\n\n## Server (`server/src/services/TeleoperationService.ts`)\n- **Session management:**\n  - `createSession(operatorId, robotId, type)`: Initialize collection session\n  - `startSession(sessionId)`: Begin recording\n  - `pauseSession(sessionId)`: Pause without ending\n  - `resumeSession(sessionId)`: Resume paused session\n  - `endSession(sessionId)`: Complete and finalize\n  - Session types: `vr_quest`, `vr_vision_pro`, `bilateral_aloha`, `kinesthetic`\n- **Trajectory recording:**\n  - Store frames at configurable FPS (30-100 Hz)\n  - Frame data: timestamp, joint_positions, joint_velocities, camera_images, action\n  - Intervention markers when operator corrects trajectory\n  - Language instruction annotation per trajectory\n- **LeRobot export:**\n  - `exportToLeRobot(sessionId)`: Generate LeRobot v3 structure\n  - Create `meta/info.json`, `meta/stats.json`, `meta/episodes.json`\n  - Convert frames to Parquet tables\n  - Upload to RustFS datasets bucket\n- **Quality feedback:**\n  - Real-time smoothness indicator during collection\n  - Warn on jerky movements\n  - Suggest retake for low-quality segments\n\n## Robot Agent (`robot-agent/src/teleoperation/`)\n- **teleop-server.ts:**\n  - WebSocket server for receiving teleop commands\n  - Command types: `joint_target`, `cartesian_target`, `gripper`\n  - Rate limiting to prevent overload\n  - Echo state back to operator\n- **teleop-recorder.ts:**\n  - Buffer frames in memory with ring buffer\n  - Periodic flush to server\n  - Camera frame capture integration\n  - Timestamp synchronization\n- **bilateral-adapter.ts:**\n  - Interface for leader-follower arm mapping\n  - Joint-to-joint correspondence\n  - Gravity compensation awareness\n\n## Database (`server/prisma/schema.prisma`)\n```prisma\nmodel TeleoperationSession {\n  id            String   @id @default(uuid())\n  operatorId    String\n  robotId       String\n  type          String   // vr_quest, bilateral_aloha, etc.\n  status        String   // created, recording, paused, completed\n  startedAt     DateTime?\n  endedAt       DateTime?\n  frameCount    Int      @default(0)\n  duration      Float?   // seconds\n  fps           Int      @default(30)\n  languageInstr String?\n  qualityScore  Float?\n  exportedDatasetId String?\n  createdAt     DateTime @default(now())\n}\n\nmodel TeleoperationFrame {\n  id            String   @id @default(uuid())\n  sessionId     String\n  timestamp     Float    // seconds from session start\n  jointPositions Json    // array of floats\n  jointVelocities Json?\n  action        Json     // commanded action\n  imagePath     String?  // RustFS path to camera frame\n  isIntervention Boolean @default(false)\n  session       TeleoperationSession @relation(...)\n}\n```\n\n**Key Files:**\n- `server/src/services/TeleoperationService.ts` - Session management\n- `server/src/routes/teleoperation.routes.ts` - REST API\n- `robot-agent/src/teleoperation/teleop-server.ts` - Robot-side server\n- `robot-agent/src/teleoperation/teleop-recorder.ts` - Frame recording\n- `app/src/features/datacollection/` - Collection UI\n- Update `server/prisma/schema.prisma` - Add models",
        "testStrategy": "Test session lifecycle (create  start  record frames  end). Test frame recording at 30 Hz without drops. Test pause/resume preserves session state. Test LeRobot export creates valid structure (validate with LeRobot tools). Test intervention markers are recorded. Test quality feedback updates during collection. Test WebSocket command handling on robot agent.",
        "priority": "high",
        "dependencies": [
          "37",
          "46"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-17T01:32:07.413Z"
      },
      {
        "id": "55",
        "title": "Synthetic Data Generation Pipeline - Isaac Lab Integration (VLA Data)",
        "description": "Integrate Isaac Lab for synthetic trajectory generation with domain randomization, sim-to-real validation, and LeRobot format export.",
        "details": "**VLA Data Strategy Phase 2: Simulation (21 SP)**\n\nIntegrate Isaac Lab for scalable synthetic data generation.\n\n## Server (`server/src/services/SyntheticDataService.ts`)\n- **Job management:**\n  - `submitGenerationJob(config)`: Submit Isaac Lab job\n  - `getJobStatus(jobId)`: Query progress\n  - `cancelJob(jobId)`: Cancel running job\n  - `listJobs(filters)`: List with status filter\n- **Configuration:**\n  - SyntheticJobConfig with task, embodiment, trajectoryCount, domainRandomization\n  - DomainRandomizationConfig with physics, visual, sensor noise params\n- **Output processing:**\n  - Convert Isaac Lab output to LeRobot v3 format\n  - Validate synthetic trajectories\n  - Compute statistics\n  - Upload to RustFS\n- **Sim-to-real validation:**\n  - Track metrics: success rate on sim, success rate on real\n  - A/B testing framework for synthetic data effectiveness\n  - Domain gap analysis\n\n## Server (`server/src/workers/synthetic-data.worker.ts`)\n- NATS consumer for `jobs.synthetic.generate`\n- Call external Isaac Lab service via REST/gRPC\n- Progress reporting to KV store\n- Handle job completion and failure\n\n## Server (`server/src/routes/synthetic.routes.ts`)\n- `POST /api/synthetic/jobs` - Submit generation job\n- `GET /api/synthetic/jobs` - List jobs\n- `GET /api/synthetic/jobs/:id` - Get job details with progress\n- `POST /api/synthetic/jobs/:id/cancel` - Cancel job\n- `GET /api/synthetic/templates` - Preset DR configurations\n- `POST /api/synthetic/validate-sim-to-real` - Record validation result\n\n## Database (`server/prisma/schema.prisma`)\n```prisma\nmodel SyntheticJob {\n  id            String   @id @default(uuid())\n  task          String\n  embodiment    String\n  trajectoryCount Int\n  config        Json     // DomainRandomizationConfig\n  status        String\n  progress      Int      @default(0)\n  outputDatasetId String?\n  errorMessage  String?\n  startedAt     DateTime?\n  completedAt   DateTime?\n  createdAt     DateTime @default(now())\n}\n```\n\n**Key Files:**\n- `server/src/services/SyntheticDataService.ts` - Job management\n- `server/src/workers/synthetic-data.worker.ts` - Job processor\n- `server/src/routes/synthetic.routes.ts` - REST API\n- `server/src/types/synthetic.types.ts` - Type definitions",
        "testStrategy": "Test job submission creates database record and NATS message. Test progress updates flow through KV store. Test cancellation stops job. Test output converts to valid LeRobot format. Test domain randomization config validation. Test sim-to-real metrics are recorded and queryable. Mock Isaac Lab service for unit tests.",
        "priority": "medium",
        "dependencies": [
          "37",
          "39",
          "41"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-17T01:35:17.439Z"
      },
      {
        "id": "56",
        "title": "Fleet Learning Infrastructure - Federated Averaging (VLA Data)",
        "description": "Implement federated learning for privacy-preserving model improvement with FedAvg, differential privacy, and Return on Human Effort (ROHE) metrics.",
        "details": "**VLA Data Strategy Phase 3: Fleet Learning (34 SP)**\n\nImplement federated learning for privacy-preserving fleet-wide model improvement.\n\n## Server (`server/src/services/FederatedLearningService.ts`)\n- **Round management:**\n  - `createRound(config)`: Initialize federated round\n  - `selectParticipants(roundId, criteria)`: Sample robots for round\n  - `distributeModel(roundId)`: Push global model to participants\n  - `collectUpdates(roundId)`: Gather model updates\n  - `aggregateUpdates(roundId)`: Run FedAvg aggregation\n  - `finalizeRound(roundId)`: Complete and publish new global model\n- **FedAvg implementation:**\n  - Weight by local sample count: `w_global = (n_i/n_total) * w_i`\n  - Handle stragglers (timeout after threshold)\n  - Minimum participants requirement\n- **Privacy mechanisms:**\n  - Differential privacy: Gaussian noise injection\n  - Privacy budget (epsilon) tracking per robot\n  - Secure aggregation (additive masking, optional)\n- **ROHE metrics (Return on Human Effort):**\n  - Track interventions per robot\n  - Measure performance improvement per intervention\n  - Compare fleet performance before/after rounds\n\n## Robot Agent (`robot-agent/src/federated/`)\n- **local-trainer.ts:** On-device fine-tuning (LoRA-based)\n- **gradient-uploader.ts:** Upload model updates with local DP noise\n- **differential-privacy.ts:** Gradient clipping and noise injection\n\n## Database (`server/prisma/schema.prisma`)\n```prisma\nmodel FederatedRound {\n  id                String   @id @default(uuid())\n  status            String   // created, selecting, training, aggregating, completed, failed\n  globalModelVersion String\n  newModelVersion   String?\n  minParticipants   Int\n  maxParticipants   Int\n  timeout           Int      // seconds\n  privacyEpsilon    Float?\n  aggregationMethod String   @default(\"fedavg\")\n  startedAt         DateTime?\n  completedAt       DateTime?\n  createdAt         DateTime @default(now())\n  participants      FederatedParticipant[]\n}\n\nmodel FederatedParticipant {\n  id            String   @id @default(uuid())\n  roundId       String\n  robotId       String\n  status        String   // selected, training, uploaded, failed, timeout\n  localSamples  Int?\n  uploadedAt    DateTime?\n  round         FederatedRound @relation(...)\n}\n\nmodel RobotPrivacyBudget {\n  robotId       String   @id\n  totalEpsilon  Float    @default(10.0)\n  usedEpsilon   Float    @default(0.0)\n  lastUpdated   DateTime @default(now())\n}\n```\n\n**Key Files:**\n- `server/src/services/FederatedLearningService.ts` - Round orchestration\n- `server/src/routes/federated.routes.ts` - REST API\n- `server/src/types/federated.types.ts` - Type definitions\n- `robot-agent/src/federated/` - Local training components",
        "testStrategy": "Test round creation and participant selection. Test model distribution reaches selected robots. Test FedAvg produces weighted average (verify with known weights). Test differential privacy adds correct noise level. Test privacy budget decrements and blocks exhausted robots. Test straggler timeout excludes slow robots. Test ROHE metrics correlate with intervention data. Test convergence over multiple rounds in simulation.",
        "priority": "medium",
        "dependencies": [
          "38",
          "40",
          "46"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-17T01:40:13.625Z"
      },
      {
        "id": "57",
        "title": "Data Curation & Augmentation Pipeline (VLA Data)",
        "description": "Implement dataset balancing (Re-Mix), task taxonomy management, quality-based curation, hindsight relabeling, and augmentation techniques.",
        "details": "**VLA Data Strategy Phase 2: Curation (21 SP)**\n\nImplement data curation and augmentation for training optimization.\n\n## Server (`server/src/services/DataCurationService.ts`)\n- **Dataset balancing (Re-Mix style):**\n  - `analyzeDistribution(datasetId)`: Task/environment distribution\n  - `computeOptimalWeights(datasetId)`: DRO-based sampling weights\n  - `createBalancedSubset(datasetId, config)`: Generate balanced dataset\n  - Maximize worst-case performance across task groups\n- **Task taxonomy:**\n  - Hierarchical structure: primitive  composed  long-horizon\n  - `categorizeTrajectory(trajectory)`: Auto-assign taxonomy level\n  - `getTaskDistribution(datasetId)`: Distribution by taxonomy\n  - Environment and scene cataloging\n- **Quality-based curation:**\n  - `filterByQuality(datasetId, minScore)`: Remove low-quality demos\n  - `removeDuplicates(datasetId, similarityThreshold)`: Deduplicate\n  - `identifyHarmful(datasetId)`: Flag potentially harmful demos (CUPID-style)\n- **Hindsight relabeling:**\n  - `relabelFailedTrajectories(datasetId)`: Goal-conditioned relabeling\n  - Generate positive signal from partial successes\n  - Update language instructions to match achieved goals\n\n## Server (`server/src/services/DataAugmentationService.ts`)\n- **Action augmentation:**\n  - `addGaussianNoise(trajectory, scale)`: MimicGen-style (default 0.05)\n  - `applyTemporalJitter(trajectory, jitterMs)`: Slight timing variations\n  - `interpolateActions(trajectory, factor)`: Smooth trajectory\n- **Image augmentation:**\n  - `augmentImages(frames, config)`: Color jitter, crops, flips\n  - `randomizeBackgrounds(frames)`: Background substitution\n  - Placeholder for generative augmentation (ROSIE-style)\n- **Language augmentation:**\n  - `paraphraseInstructions(dataset)`: LLM-based paraphrasing\n  - `chainSkillInstructions(dataset)`: Combine primitives\n  - `computeDiversityScore(dataset)`: Measure instruction variety\n\n## Server (`server/src/routes/curation.routes.ts`)\n- `GET /api/datasets/:id/distribution` - Task distribution analysis\n- `POST /api/datasets/:id/balance` - Create balanced subset\n- `POST /api/datasets/:id/augment` - Apply augmentation pipeline\n- `POST /api/datasets/:id/curate` - Run curation pipeline\n- `GET /api/taxonomy` - Browse task taxonomy\n- `POST /api/taxonomy/categorize` - Categorize trajectory\n- `GET /api/datasets/:id/duplicates` - Find near-duplicates\n- `POST /api/datasets/:id/relabel-hindsight` - Hindsight relabeling\n\n**Key Files:**\n- `server/src/services/DataCurationService.ts` - Curation logic\n- `server/src/services/DataAugmentationService.ts` - Augmentation logic\n- `server/src/routes/curation.routes.ts` - REST API\n- `server/src/types/curation.types.ts` - Type definitions",
        "testStrategy": "Test distribution analysis identifies imbalanced datasets. Test Re-Mix weights increase minority class sampling. Test balanced subset has more uniform distribution. Test quality filter removes demos below threshold. Test duplicate detection finds near-identical trajectories. Test Gaussian noise augmentation preserves trajectory shape. Test language paraphrasing produces diverse instructions. Test hindsight relabeling creates valid new instructions.",
        "priority": "medium",
        "dependencies": [
          "41",
          "53"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-17T01:42:53.209Z"
      },
      {
        "id": "58",
        "title": "Training Data Compliance Documentation (VLA Compliance)",
        "description": "Implement EU AI Act GPAI training data documentation with dataset provenance, training data summary template, bias documentation, and version management.",
        "details": "**VLA Data Strategy Phase 3: Compliance (13 SP)**\n\nImplement training data documentation per EU AI Act requirements.\n\n## Server (`server/src/services/TrainingDataDocService.ts`)\n- **Dataset provenance tracking:**\n  - `recordProvenance(datasetId, provenance)`: Document source\n  - Source types: `collected`, `purchased`, `synthetic`, `open_source`, `contributed`\n  - Collection methodology documentation\n  - Labeling procedures and annotator info\n  - Data cleaning steps applied\n  - Chain of custody tracking\n- **Training data summary (AI Act GPAI template):**\n  - `generateSummary(modelVersionId)`: Create AI Act summary\n  - List all datasets used in training\n  - Public vs private classification\n  - Web scraping sources (if any)\n  - Copyright compliance measures\n  - Data processing purposes\n- **Bias and gap documentation:**\n  - `recordBiasAssessment(modelVersionId, assessment)`: Store assessment\n  - Demographic coverage analysis fields\n  - Known limitations and gaps\n  - Potential bias sources\n  - Mitigation measures applied\n- **Version and update management:**\n  - Track which data versions used per training run\n  - MLflow lineage integration\n  - 6-month update tracking (AI Act requirement)\n  - Alert when update is due\n\n## Database (`server/prisma/schema.prisma`)\n```prisma\nmodel DatasetProvenance {\n  id              String   @id @default(uuid())\n  datasetId       String   @unique\n  sourceType      String\n  sourceName      String?\n  sourceUrl       String?\n  collectionMethod String?\n  labelingProcedure String?\n  cleaningSteps   Json?    // string[]\n  licenseType     String?\n  copyrightCompliance String?\n  recordedAt      DateTime @default(now())\n  recordedBy      String\n}\n\nmodel TrainingDataSummary {\n  id              String   @id @default(uuid())\n  modelVersionId  String   @unique\n  datasetIds      Json     // string[]\n  totalTrajectories Int\n  copyrightMeasures String\n  processingPurposes Json  // string[]\n  knownGaps       Json     // string[]\n  generatedAt     DateTime @default(now())\n  lastUpdated     DateTime @default(now())\n  nextUpdateDue   DateTime\n}\n\nmodel BiasAssessment {\n  id              String   @id @default(uuid())\n  modelVersionId  String\n  demographicCoverage Json\n  knownLimitations Json    // string[]\n  potentialBiasSources Json // string[]\n  mitigationMeasures Json  // string[]\n  assessedBy      String\n  assessmentDate  DateTime @default(now())\n}\n```\n\n**Key Files:**\n- `server/src/services/TrainingDataDocService.ts` - Documentation logic\n- `server/src/routes/training-docs.routes.ts` - REST API\n- `server/src/types/training-docs.types.ts` - Type definitions\n- Update `server/prisma/schema.prisma` - Add models",
        "testStrategy": "Test provenance recording stores all required fields. Test summary generation includes all datasets used in training. Test 6-month update due date calculation. Test update-due alert triggers correctly. Test bias assessment stores and retrieves properly. Test export generates valid markdown/PDF. Test MLflow lineage links are preserved.",
        "priority": "high",
        "dependencies": [
          "24",
          "41"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-17T01:48:00.727Z"
      },
      {
        "id": "59",
        "title": "Active Learning System (VLA Data)",
        "description": "Implement uncertainty-based data collection prioritization with MUSEL-inspired framework, learning progress metrics, and collection recommendations.",
        "details": "**VLA Data Strategy Phase 3: Active Learning (13 SP)**\n\nImplement active learning for targeted data collection prioritization.\n\n## Server (`server/src/services/ActiveLearningService.ts`)\n- **Uncertainty estimation:**\n  - `logPrediction(modelId, input, output, confidence)`: Store prediction\n  - `computeEpistemicUncertainty(modelId, task)`: Ensemble disagreement\n  - `aggregateUncertainty(modelId, groupBy)`: By task/environment\n  - High uncertainty = model needs more data\n- **Learning progress tracking:**\n  - `trackImprovementRate(modelId)`: Performance delta over time\n  - `identifyPlateaus(modelId)`: Tasks where improvement stalled\n  - Plateau = need more diverse data, not just more data\n- **MUSEL-inspired priority scoring:**\n  - Predictive uncertainty (model confidence)\n  - Input diversity (distance to existing data)\n  - Learning progress (recent improvement rate)\n  - Combined score: `priority = w1*uncertainty + w2*diversity + w3*(1-progress)`\n- **Collection recommendations:**\n  - `getCollectionPriorities()`: Ranked list of targets\n  - `estimateDemosNeeded(target)`: How many demos to collect\n  - `trackCollectionProgress(target)`: Progress vs recommendation\n  - Update priorities as new data arrives\n\n## Database (`server/prisma/schema.prisma`)\n```prisma\nmodel PredictionLog {\n  id            String   @id @default(uuid())\n  modelId       String\n  robotId       String\n  timestamp     DateTime @default(now())\n  inputHash     String\n  taskCategory  String\n  environment   String\n  confidence    Float\n  wasCorrect    Boolean?\n  @@index([modelId, taskCategory])\n  @@index([modelId, environment])\n}\n\nmodel CollectionTarget {\n  id            String   @id @default(uuid())\n  targetType    String   // task, environment\n  targetName    String\n  priorityScore Float\n  estimatedDemos Int\n  collectedDemos Int     @default(0)\n  status        String   // active, completed, paused\n  createdAt     DateTime @default(now())\n  updatedAt     DateTime @updatedAt\n}\n```\n\n**Key Files:**\n- `server/src/services/ActiveLearningService.ts` - Core logic\n- `server/src/routes/active-learning.routes.ts` - REST API\n- `server/src/types/active-learning.types.ts` - Type definitions",
        "testStrategy": "Test prediction logging stores all fields correctly. Test uncertainty aggregation groups by task/environment. Test priority scoring combines components correctly. Test recommendations update as new data is collected. Test progress tracking shows uncertainty reduction. Test robot agent reports confidence with predictions. Test heatmap visualization renders correctly.",
        "priority": "medium",
        "dependencies": [
          "41",
          "53"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-17T01:56:32.860Z"
      },
      {
        "id": "60",
        "title": "Customer Data Contribution Portal (VLA Data)",
        "description": "Implement customer data contribution system with upload workflow, incentive credits, impact tracking, and contribution leaderboard.",
        "details": "**VLA Data Strategy Phase 4: Data Flywheel (21 SP)**\n\nImplement customer data contribution for fleet learning data flywheel.\n\n## Server (`server/src/services/DataContributionService.ts`)\n- **Contribution workflow:**\n  - `initiateContribution(userId, metadata)`: Start contribution\n  - `uploadContributionData(contributionId, data)`: Upload dataset\n  - `validateContribution(contributionId)`: Quality validation\n  - `reviewContribution(contributionId, decision)`: Privacy review\n  - `acceptContribution(contributionId)`: Accept into training pool\n  - `rejectContribution(contributionId, reason)`: Reject with feedback\n- **Consent and licensing:**\n  - License options: `exclusive`, `non_exclusive`, `limited`\n  - Consent tracking for data usage\n  - Revocation support (remove from future training)\n- **Credit system:**\n  - `calculateCredits(contribution)`: Based on quantity and quality\n  - `awardCredits(contributionId)`: Add to user account\n  - `getCreditsBalance(userId)`: Current balance\n  - `redeemCredits(userId, reward)`: Use credits for rewards\n  - Credit formula: `credits = trajectories * quality_score * rarity_bonus`\n- **Impact tracking:**\n  - `trackModelInclusion(contributionId, modelVersionId)`: Record usage\n  - `computeImpactScore(contributionId)`: How much did it help?\n  - `getContributionImpact(contributionId)`: Detailed impact report\n  - Impact = improvement delta attributable to contribution\n\n## Database (`server/prisma/schema.prisma`)\n```prisma\nmodel DataContribution {\n  id              String   @id @default(uuid())\n  userId          String\n  organizationId  String?\n  status          String\n  datasetId       String?  @unique\n  trajectoryCount Int\n  qualityScore    Float?\n  licenseType     String\n  consentGrantedAt DateTime\n  metadata        Json\n  creditsAwarded  Int?\n  rejectionReason String?\n  reviewedBy      String?\n  reviewedAt      DateTime?\n  createdAt       DateTime @default(now())\n  updatedAt       DateTime @updatedAt\n  credits         ContributionCredit[]\n  impacts         ContributionImpact[]\n}\n\nmodel ContributionCredit {\n  id              String   @id @default(uuid())\n  userId          String\n  amount          Int\n  reason          String\n  contributionId  String?\n  contribution    DataContribution? @relation(...)\n  awardedAt       DateTime @default(now())\n  @@index([userId])\n}\n\nmodel ContributionImpact {\n  id              String   @id @default(uuid())\n  contributionId  String\n  modelVersionId  String\n  trajectoriesUsed Int\n  impactScore     Float\n  contribution    DataContribution @relation(...)\n  recordedAt      DateTime @default(now())\n}\n```\n\n**Key Files:**\n- `server/src/services/DataContributionService.ts` - Contribution logic\n- `server/src/routes/contributions.routes.ts` - REST API\n- `server/src/types/contribution.types.ts` - Type definitions\n- `app/src/features/contributions/` - Contribution UI feature module",
        "testStrategy": "Test contribution workflow from initiation to acceptance. Test quality validation runs automatically. Test credit calculation formula. Test credits are awarded on acceptance. Test impact tracking records model usage. Test leaderboard ranks by total credits. Test consent revocation removes from future training. Test license types are enforced.",
        "priority": "low",
        "dependencies": [
          "41",
          "56"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "61",
        "title": "Teleoperation Robot Agent Modules (VLA Data)",
        "description": "Implement teleoperation modules on robot-agent for receiving teleop commands, recording frames, and supporting bilateral (ALOHA-style) control.",
        "details": "**VLA Data Collection Infrastructure - Robot Side**\n\nImplement the robot-agent side of teleoperation data collection.\n\n## Robot Agent (`robot-agent/src/teleoperation/`)\n\n### teleop-server.ts\n- **WebSocket server for teleop commands:**\n  - Listen on configurable port (default 8765)\n  - Command types: `joint_target`, `cartesian_target`, `gripper`, `pause`, `resume`\n  - Rate limiting to prevent overload (max 100 Hz)\n  - Echo current state back to operator for latency display\n  - Authentication via session token\n  - Graceful disconnection handling\n\n### teleop-recorder.ts\n- **Frame recording with ring buffer:**\n  - Ring buffer for recent N frames (configurable, default 1000)\n  - Store: timestamp, joint_positions, joint_velocities, action, camera frames\n  - Periodic flush to server via REST API (configurable interval)\n  - Camera frame capture integration (resize, compress to JPEG)\n  - Timestamp synchronization with server clock\n  - Intervention marker support (operator can flag corrections)\n  - Memory-efficient storage with typed arrays\n\n### bilateral-adapter.ts\n- **Leader-follower arm mapping:**\n  - Interface for ALOHA-style bilateral teleop\n  - Joint-to-joint correspondence mapping\n  - Gravity compensation awareness\n  - Position/velocity mode switching\n  - Force feedback channel (if hardware supports)\n  - Workspace scaling factors\n\n## Integration\n- Export teleoperation module from robot-agent\n- Add teleoperation config to robot-agent config\n- Connect to SafetyMonitor for E-stop during teleop\n\n**Key Files:**\n- `robot-agent/src/teleoperation/teleop-server.ts` (NEW)\n- `robot-agent/src/teleoperation/teleop-recorder.ts` (NEW)\n- `robot-agent/src/teleoperation/bilateral-adapter.ts` (NEW)\n- `robot-agent/src/teleoperation/index.ts` (NEW)\n- `robot-agent/src/config/config.ts` (UPDATE)",
        "testStrategy": "Test WebSocket server accepts connections and rate limits. Test frame recording stores correct data types. Test ring buffer evicts oldest frames. Test periodic flush sends to server. Test bilateral adapter maps joints correctly. Test intervention markers are recorded. Test E-stop halts teleop session.",
        "priority": "high",
        "dependencies": [
          "54"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "62",
        "title": "LeRobot Export Implementation (VLA Data)",
        "description": "Replace the stub exportToLeRobot() implementation with full Parquet conversion, metadata generation, and RustFS upload for LeRobot v3 format.",
        "details": "**VLA Data Collection - LeRobot Export**\n\nImplement actual LeRobot v3 format export for teleoperation sessions.\n\n## Server (`server/src/services/TeleoperationService.ts`)\n\n### exportToLeRobot() - Full Implementation\n**Currently:** Returns stub response with random dataset ID\n**Needs:** Full LeRobot v3 export\n\n1. **Parquet Table Generation:**\n   - Install: `npm install parquetjs` or `@apache-arrow/parquet`\n   - Convert frames to columnar format:\n     - `observation.state`: Float32 array for joint positions\n     - `action`: Float32 array for commanded actions\n     - `timestamp`: Float64 for frame timestamps\n   - Create `data/train-00000.parquet` file\n\n2. **Metadata File Generation:**\n   - `meta/info.json`:\n     ```json\n     {\n       \"codebase_version\": \"v3.0\",\n       \"robot_type\": \"<embodiment_tag>\",\n       \"fps\": 30,\n       \"features\": { ... },\n       \"total_episodes\": 1,\n       \"total_frames\": <frame_count>\n     }\n     ```\n   - `meta/stats.json`: Compute mean/std per feature from frames\n   - `meta/episodes.json`: Episode boundaries (single episode per session)\n\n3. **RustFS Upload:**\n   - Use existing `rustfsClient` from `storage/rustfs-client.ts`\n   - Upload to `datasets/<dataset_id>/` bucket\n   - Structure:\n     ```\n     datasets/<uuid>/\n       meta/info.json\n       meta/stats.json\n       meta/episodes.json\n       data/train-00000.parquet\n       videos/observation.images.*/episode_0.mp4 (optional)\n     ```\n\n4. **Validation:**\n   - Verify Parquet schema matches LeRobot spec\n   - Check all required metadata fields present\n   - Validate frame count consistency\n\n**Key Files:**\n- `server/src/services/TeleoperationService.ts` (UPDATE - exportToLeRobot method)\n- `server/package.json` (UPDATE - add parquetjs dependency)",
        "testStrategy": "Test Parquet file is valid and readable. Test info.json has all required fields. Test stats.json has correct mean/std values. Test episodes.json boundaries match frame counts. Test upload to RustFS succeeds. Test exported dataset is readable by LeRobot tools.",
        "priority": "high",
        "dependencies": [
          "54",
          "61"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "63",
        "title": "Synthetic Data NATS Worker (VLA Data)",
        "description": "Implement NATS-based background worker for synthetic data generation jobs, replacing the simulated job execution with actual job queue processing.",
        "details": "**VLA Data Pipeline - NATS Worker for Synthetic Generation**\n\nReplace simulateJobExecution() with real NATS-based job processing.\n\n## Server (`server/src/messaging/streams.ts`)\n\n### Add Synthetic Stream\n```typescript\nSTREAM_NAMES.SYNTHETIC_GENERATION = 'SYNTHETIC_GENERATION'\nSUBJECTS.SYNTHETIC_GENERATE = 'jobs.synthetic.generate'\nCONSUMER_NAMES.SYNTHETIC_WORKERS = 'synthetic-workers'\n```\n\n## Server (`server/src/workers/synthetic-generation.worker.ts`)\n\n### Worker Implementation\n```typescript\nexport const syntheticWorker = {\n  start: startSyntheticWorker,\n  stop: stopSyntheticWorker,\n  isRunning: () => isRunning\n}\n\nasync function startSyntheticWorker(): Promise<void> {\n  // Get JetStream consumer\n  // Listen for jobs.synthetic.generate messages\n  // For each message:\n  //   1. Parse SyntheticJobMessage\n  //   2. Update job status to 'queued'\n  //   3. Call IsaacLabClient.submitJob() (or mock for now)\n  //   4. Poll for progress OR wait for webhook\n  //   5. Update progress via syntheticDataService.updateJobProgress()\n  //   6. On complete: syntheticDataService.completeJob()\n  //   7. On failure: syntheticDataService.failJob()\n  //   8. ACK message\n}\n```\n\n## Server (`server/src/services/SyntheticDataService.ts`)\n\n### Update submitJob()\n- Replace `simulateJobExecution()` with NATS publish:\n```typescript\nawait natsClient.publish('jobs.synthetic.generate', {\n  jobId: job.id,\n  config: job.config,\n  callbackUrl: `${process.env.SERVER_URL}/api/synthetic/workers/callback`\n});\n```\n\n## Server (`server/src/routes/synthetic.routes.ts`)\n\n### Add Worker Callbacks\n```typescript\nPOST /api/synthetic/workers/progress\nPOST /api/synthetic/workers/complete\nPOST /api/synthetic/workers/failed\n```\n\n## Server (`server/src/index.ts`)\n\n### Initialize Worker\n```typescript\nimport { syntheticWorker } from './workers/synthetic-generation.worker.js';\nawait syntheticWorker.start();\n```\n\n**Key Files:**\n- `server/src/workers/synthetic-generation.worker.ts` (NEW)\n- `server/src/messaging/streams.ts` (UPDATE)\n- `server/src/services/SyntheticDataService.ts` (UPDATE - remove simulate)\n- `server/src/routes/synthetic.routes.ts` (UPDATE - add worker callbacks)\n- `server/src/index.ts` (UPDATE - start worker)",
        "testStrategy": "Test job submission publishes to NATS. Test worker consumes and processes jobs. Test progress updates flow through. Test job completion marks database record. Test job failure updates status and error message. Test worker handles NATS disconnection. Test dead-letter queue receives failed jobs after retries.",
        "priority": "high",
        "dependencies": [
          "55"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "64",
        "title": "Isaac Lab REST Client (VLA Data)",
        "description": "Implement REST client for Isaac Lab synthetic data generation service with job submission, status polling, cancellation, and output retrieval.",
        "details": "**VLA Data Pipeline - Isaac Lab Integration**\n\nCreate REST client to communicate with Isaac Lab synthetic generation service.\n\n## Server (`server/src/services/IsaacLabClient.ts`)\n\n### Client Implementation\n```typescript\nexport class IsaacLabClient {\n  private baseUrl: string;\n  private apiKey?: string;\n  private httpClient: AxiosInstance;\n\n  constructor() {\n    this.baseUrl = process.env.ISAAC_LAB_ENDPOINT || 'http://localhost:8100';\n    this.apiKey = process.env.ISAAC_LAB_API_KEY;\n  }\n\n  // Submit synthetic generation job\n  async submitJob(request: IsaacLabRequest): Promise<{ jobId: string }>\n\n  // Get job status and progress\n  async getJobStatus(jobId: string): Promise<IsaacLabJobStatus>\n\n  // Cancel running job\n  async cancelJob(jobId: string): Promise<void>\n\n  // Get generated output path\n  async getJobOutput(jobId: string): Promise<{ outputPath: string; trajectoryCount: number }>\n\n  // Health check\n  async healthCheck(): Promise<{ status: 'healthy' | 'degraded' | 'unhealthy' }>\n}\n\ninterface IsaacLabRequest {\n  task: string;\n  embodiment: string;\n  trajectoryCount: number;\n  domainRandomization: DomainRandomizationConfig;\n  simulation: SimulationConfig;\n  callbackUrl?: string;\n}\n\ninterface IsaacLabJobStatus {\n  jobId: string;\n  status: 'pending' | 'running' | 'completed' | 'failed';\n  progress: number;\n  generatedCount: number;\n  successfulCount: number;\n  failedCount: number;\n  estimatedTimeRemaining?: number;\n  errorMessage?: string;\n  outputPath?: string;\n}\n```\n\n### Mock Mode\n- When ISAAC_LAB_ENDPOINT is 'mock' or undefined, use simulation\n- Simulate realistic job timing and progress\n- Generate mock output for testing\n\n### Error Handling\n- Retry logic for transient failures (3 retries with exponential backoff)\n- Timeout handling (configurable, default 30s per request)\n- Circuit breaker for sustained failures\n\n**Key Files:**\n- `server/src/services/IsaacLabClient.ts` (NEW)\n- `server/src/types/synthetic.types.ts` (UPDATE - add Isaac Lab types if needed)",
        "testStrategy": "Test job submission returns job ID. Test status polling returns correct progress. Test cancellation stops job. Test output retrieval returns valid path. Test health check reflects service status. Test retry logic handles transient failures. Test mock mode works for development. Test timeout handling.",
        "priority": "medium",
        "dependencies": [
          "55",
          "63"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "65",
        "title": "Federated Learning Robot Agent Modules (VLA Data)",
        "description": "Implement federated learning components on robot-agent for local model training, gradient uploading with differential privacy, and round participation.",
        "details": "**VLA Fleet Learning - Robot Side**\n\nImplement robot-agent components for federated learning participation.\n\n## Robot Agent (`robot-agent/src/federated/`)\n\n### local-trainer.ts\n- **On-device model fine-tuning:**\n  - Receive global model from server\n  - Fine-tune with local demonstration data\n  - LoRA-based training (parameter efficient)\n  - Support for VLA model architecture\n  - Training config: learning rate, epochs, batch size\n  - Memory-efficient training (gradient checkpointing)\n  - Return model delta (updated - original weights)\n\n### gradient-uploader.ts\n- **Upload model updates with privacy:**\n  - Serialize model delta to compact format\n  - Apply differential privacy noise before upload\n  - Compute update hash for verification\n  - Upload via REST API to server\n  - Retry logic for failed uploads\n  - Progress reporting during upload\n\n### differential-privacy.ts\n- **Gradient clipping and noise injection:**\n  - Clip gradients to max norm (configurable)\n  - Add Gaussian noise scaled by privacy budget\n  - Track local privacy budget consumption\n  - Prevent participation if budget exhausted\n  - Report privacy metrics to server\n\n### round-client.ts\n- **Federated round participation:**\n  - Receive round invitation from server\n  - Check eligibility (privacy budget, connectivity)\n  - Download global model\n  - Run local training\n  - Upload model update\n  - Report completion/failure\n\n**Key Files:**\n- `robot-agent/src/federated/local-trainer.ts` (NEW)\n- `robot-agent/src/federated/gradient-uploader.ts` (NEW)\n- `robot-agent/src/federated/differential-privacy.ts` (NEW)\n- `robot-agent/src/federated/round-client.ts` (NEW)\n- `robot-agent/src/federated/index.ts` (NEW)",
        "testStrategy": "Test local trainer produces valid model delta. Test gradient clipping limits norm. Test DP noise scales with epsilon. Test uploader retries on failure. Test round client handles full lifecycle. Test privacy budget prevents over-participation. Test model delta serialization roundtrips.",
        "priority": "medium",
        "dependencies": [
          "56"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "66",
        "title": "Secure Aggregation Implementation (VLA Data)",
        "description": "Implement secure aggregation for federated learning with cryptographic masking, preventing server from seeing individual model updates.",
        "details": "**VLA Fleet Learning - Secure Aggregation**\n\nAdd cryptographic protection for federated model updates.\n\n## Server (`server/src/services/SecureAggregationService.ts`)\n\n### Additive Masking Protocol\n1. **Key Exchange Phase:**\n   - Each participant generates random mask seed\n   - Participants exchange seeds pairwise (via server relay)\n   - Server cannot see seeds (encrypted end-to-end)\n\n2. **Masking Phase:**\n   - Each participant masks their update: `masked_update = update + sum(masks_to_add) - sum(masks_to_subtract)`\n   - Masks cancel out when summed: `sum(masked_updates) = sum(updates)`\n   - Server aggregates masked updates\n\n3. **Dropout Handling:**\n   - Surviving participants reveal masks for dropped participants\n   - Aggregation completes with available updates\n\n### Implementation\n```typescript\nexport class SecureAggregationService {\n  // Initialize round with participants\n  async initializeRound(roundId: string, participants: string[]): Promise<void>\n\n  // Generate and distribute pairwise seeds\n  async distributeMasks(roundId: string): Promise<Map<string, Buffer>>\n\n  // Verify masked update structure\n  async verifyMaskedUpdate(roundId: string, participantId: string, maskedUpdate: Buffer): Promise<boolean>\n\n  // Aggregate masked updates\n  async aggregateMaskedUpdates(roundId: string): Promise<Float32Array>\n\n  // Handle participant dropout\n  async handleDropout(roundId: string, droppedParticipantId: string): Promise<void>\n}\n```\n\n## Server (`server/src/services/FederatedLearningService.ts`)\n\n### Integration\n- Use SecureAggregationService when `config.secureAggregation: true`\n- Fall back to plain FedAvg when disabled\n- Store masked updates instead of plain deltas\n- Verify aggregation result\n\n**Key Files:**\n- `server/src/services/SecureAggregationService.ts` (NEW)\n- `server/src/services/FederatedLearningService.ts` (UPDATE)\n- `server/src/types/federated.types.ts` (UPDATE - add secure aggregation types)",
        "testStrategy": "Test mask generation produces random values. Test masks cancel out in sum. Test dropout handling recovers aggregation. Test aggregation result matches expected sum. Test verification rejects tampered updates. Test integration with FederatedLearningService. Test fallback to plain FedAvg when disabled.",
        "priority": "medium",
        "dependencies": [
          "56",
          "65"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "67",
        "title": "PDF Export for Training Compliance (VLA Compliance)",
        "description": "Implement PDF generation for EU AI Act training data documentation with compliance-formatted templates and digital signatures.",
        "details": "**VLA Compliance - PDF Export**\n\nAdd PDF generation capability to TrainingDataDocService.\n\n## Server (`server/src/services/TrainingDataDocService.ts`)\n\n### exportDocumentation() - PDF Format\n**Currently:** JSON and Markdown only\n**Add:** PDF generation using pdfkit or puppeteer\n\n### Option A: pdfkit (Lighter, no browser dependency)\n```typescript\nimport PDFDocument from 'pdfkit';\n\nasync exportAsPdf(data: ExportedDocument): Promise<Buffer> {\n  const doc = new PDFDocument();\n  const buffers: Buffer[] = [];\n\n  doc.on('data', buffers.push.bind(buffers));\n  doc.on('end', () => resolve(Buffer.concat(buffers)));\n\n  // Header\n  doc.fontSize(24).text('Training Data Documentation', { align: 'center' });\n  doc.fontSize(12).text(`Model Version: ${data.modelVersionId}`);\n  doc.text(`Generated: ${data.generatedAt}`);\n\n  // Summary Section\n  doc.addPage();\n  doc.fontSize(18).text('Training Data Summary');\n  // ... format summary data\n\n  // Provenance Section\n  doc.addPage();\n  doc.fontSize(18).text('Dataset Provenance');\n  // ... format provenance table\n\n  // Bias Assessment Section\n  doc.addPage();\n  doc.fontSize(18).text('Bias Assessment');\n  // ... format assessment data\n\n  doc.end();\n}\n```\n\n### Option B: puppeteer (Rich HTML rendering)\n```typescript\nimport puppeteer from 'puppeteer';\n\nasync exportAsPdf(data: ExportedDocument): Promise<Buffer> {\n  // Generate HTML from markdown\n  const html = renderComplianceTemplate(data);\n\n  // Launch headless browser\n  const browser = await puppeteer.launch();\n  const page = await browser.newPage();\n  await page.setContent(html);\n\n  // Generate PDF\n  const pdf = await page.pdf({\n    format: 'A4',\n    printBackground: true,\n    margin: { top: '1in', bottom: '1in', left: '1in', right: '1in' }\n  });\n\n  await browser.close();\n  return Buffer.from(pdf);\n}\n```\n\n### EU AI Act Compliance Template\n- Header with model version, date, organization\n- Table of Contents with page numbers\n- Training Data Summary (Art. 53)\n- Dataset Sources with license information\n- Bias Assessment and Mitigations\n- Known Limitations\n- Processing Purposes\n- Footer with page numbers and generation timestamp\n\n**Key Files:**\n- `server/src/services/TrainingDataDocService.ts` (UPDATE)\n- `server/package.json` (UPDATE - add pdfkit or puppeteer)\n- `server/src/templates/compliance-pdf.ts` (NEW - PDF template)",
        "testStrategy": "Test PDF generation produces valid PDF. Test all sections are included. Test table formatting is correct. Test images/logos render if included. Test PDF is readable by standard viewers. Test file size is reasonable. Test generation completes in reasonable time (<10s).",
        "priority": "high",
        "dependencies": [
          "58"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "68",
        "title": "Ensemble Uncertainty for Active Learning (VLA Data)",
        "description": "Implement multi-model ensemble disagreement and MC Dropout uncertainty estimation for improved active learning prioritization.",
        "details": "**VLA Active Learning - Ensemble Uncertainty**\n\nAdd proper uncertainty estimation using model ensembles.\n\n## Server (`server/src/services/ActiveLearningService.ts`)\n\n### Ensemble Disagreement\n**Currently:** Uses single-model confidence\n**Add:** Multi-model ensemble disagreement\n\n```typescript\ninterface EnsembleUncertainty {\n  modelId: string;\n  inputHash: string;\n  predictions: EnsemblePrediction[];\n  meanConfidence: number;\n  varianceConfidence: number;\n  disagreementScore: number;  // Jensen-Shannon divergence\n  epistemicUncertainty: number;  // Model uncertainty\n  aleatoric: number;  // Data uncertainty (if separable)\n}\n\ninterface EnsemblePrediction {\n  ensembleMemberId: string;\n  confidence: number;\n  actionPrediction: number[];\n}\n```\n\n### computeEnsembleUncertainty()\n```typescript\nasync computeEnsembleUncertainty(\n  modelIds: string[],  // Ensemble member model IDs\n  inputHash: string\n): Promise<EnsembleUncertainty> {\n  // Fetch predictions from all ensemble members\n  const predictions = await this.getPredictionsForInput(modelIds, inputHash);\n\n  // Compute variance across ensemble\n  const confidences = predictions.map(p => p.confidence);\n  const meanConf = mean(confidences);\n  const varianceConf = variance(confidences);\n\n  // Compute Jensen-Shannon divergence for disagreement\n  const disagreement = this.computeJSDivergence(predictions);\n\n  // Epistemic uncertainty = high variance = model doesn't know\n  const epistemic = Math.sqrt(varianceConf);\n\n  return {\n    meanConfidence: meanConf,\n    varianceConfidence: varianceConf,\n    disagreementScore: disagreement,\n    epistemicUncertainty: epistemic,\n    // ...\n  };\n}\n```\n\n### MC Dropout Uncertainty\n```typescript\n// For models that support MC Dropout:\n// Run N forward passes with dropout enabled\n// Compute variance across passes\nasync computeMCDropoutUncertainty(\n  modelId: string,\n  inputHash: string,\n  numPasses: number = 10\n): Promise<number> {\n  // This would be called from robot-agent during inference\n  // Robot logs multiple passes, server aggregates\n  const passes = await this.getMCDropoutPasses(modelId, inputHash);\n  return this.computeVariance(passes);\n}\n```\n\n### Integration with Priority Scoring\n- Update `computeCollectionPriorities()` to use ensemble uncertainty\n- Higher epistemic uncertainty = higher priority for data collection\n- Track uncertainty trends over time\n\n## Robot Agent Integration\n- Robot agent should log predictions from ensemble members\n- Support MC Dropout mode during inference\n- Report ensemble uncertainty back to server\n\n**Key Files:**\n- `server/src/services/ActiveLearningService.ts` (UPDATE)\n- `server/src/types/active-learning.types.ts` (UPDATE - add ensemble types)\n- `robot-agent/src/vla/vla-controller.ts` (UPDATE - log ensemble predictions)",
        "testStrategy": "Test ensemble predictions are aggregated correctly. Test variance computation is accurate. Test JS divergence produces valid values (0-1). Test high disagreement increases priority score. Test MC Dropout aggregation works. Test integration with robot-agent prediction logging. Test uncertainty trends track over time.",
        "priority": "medium",
        "dependencies": [
          "59"
        ],
        "status": "pending",
        "subtasks": []
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2026-01-17T12:00:00.000Z",
      "taskCount": 68,
      "completedCount": 48,
      "tags": [
        "master"
      ]
    }
  }
}