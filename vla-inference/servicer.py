"""
@file servicer.py
@description VLA inference gRPC servicer with model-agnostic architecture
@feature vla-inference
"""

import time
import asyncio
import logging
from typing import AsyncIterator, Optional

# Import generated proto code (will be generated by build script)
try:
    from proto import vla_inference_pb2, vla_inference_pb2_grpc
except ImportError:
    # For development before proto generation
    vla_inference_pb2 = None
    vla_inference_pb2_grpc = None

# GPU monitoring (optional)
try:
    import pynvml
    HAS_PYNVML = True
except ImportError:
    HAS_PYNVML = False

from models import create_model, VLAModel, Observation, ActionChunk
from config import VLAConfig, get_config
from metrics import get_metrics, VLAMetrics

logger = logging.getLogger(__name__)


class VLAInferenceServicer:
    """
    gRPC servicer for VLA inference with model-agnostic architecture.

    Supports multiple VLA model backends:
    - Ï€0.6 (pi0) - Physical Intelligence's foundation model
    - OpenVLA 7B (openvla) - Open-source alternative
    - GR00T (groot) - NVIDIA's humanoid model (future)

    Model selection via VLA_MODEL_TYPE environment variable.
    """

    def __init__(
        self,
        config: Optional[VLAConfig] = None,
        model: Optional[VLAModel] = None,
    ):
        """
        Initialize the VLA inference servicer.

        Args:
            config: Configuration (defaults to env-based config)
            model: Pre-created model instance (for testing)
        """
        self.config = config or get_config()
        self.metrics = get_metrics()

        # Initialize model
        if model is not None:
            self._model = model
        else:
            self._model = self._create_and_load_model()

        # Metrics tracking
        self.start_time = time.time()
        self.total_requests = 0
        self.latency_sum = 0.0
        self.queue_depth = 0

        # Initialize GPU monitoring
        self._init_gpu_monitoring()

        # Set model info in metrics
        if self._model.is_loaded:
            info = self._model.model_info
            self.metrics.set_model_info(
                model_name=info.model_name,
                model_version=info.model_version,
                base_model=info.base_model,
                device=self._model.device,
            )

    def _create_and_load_model(self) -> VLAModel:
        """Create and load model based on configuration."""
        logger.info(f"Creating model: {self.config.model_type}")

        try:
            model = create_model(self.config.model_type)
            model.load(
                checkpoint_path=self.config.model_path,
                device=self.config.device,
            )
            return model
        except NotImplementedError as e:
            # GR00T or other unavailable model
            logger.error(f"Model not available: {e}")
            raise
        except Exception as e:
            logger.error(f"Failed to load model: {e}")
            raise

    def _init_gpu_monitoring(self) -> None:
        """Initialize GPU monitoring with pynvml."""
        if HAS_PYNVML:
            try:
                pynvml.nvmlInit()
                self.gpu_handle = pynvml.nvmlDeviceGetHandleByIndex(0)
                logger.info("GPU monitoring initialized")
            except Exception as e:
                logger.warning(f"Failed to initialize GPU monitoring: {e}")
                self.gpu_handle = None
        else:
            self.gpu_handle = None

    def _get_gpu_stats(self) -> tuple[float, float, int, int]:
        """
        Get GPU utilization and memory usage.

        Returns:
            Tuple of (gpu_util%, memory_util%, memory_used_bytes, memory_total_bytes)
        """
        if self.gpu_handle is None:
            return 0.0, 0.0, 0, 0

        try:
            util = pynvml.nvmlDeviceGetUtilizationRates(self.gpu_handle)
            memory = pynvml.nvmlDeviceGetMemoryInfo(self.gpu_handle)
            return (
                float(util.gpu),
                (memory.used / memory.total) * 100,
                memory.used,
                memory.total,
            )
        except Exception as e:
            logger.warning(f"Failed to get GPU stats: {e}")
            return 0.0, 0.0, 0, 0

    def _observation_from_proto(self, request) -> Observation:
        """Convert proto Observation to domain Observation."""
        return Observation(
            camera_image=bytes(request.camera_image),
            joint_positions=list(request.joint_positions),
            joint_velocities=list(request.joint_velocities),
            language_instruction=request.language_instruction,
            timestamp=request.timestamp,
            embodiment_tag=request.embodiment_tag,
            session_id=request.session_id if request.session_id else None,
        )

    def _action_chunk_to_proto(self, chunk: ActionChunk, base_timestamp: float):
        """Convert domain ActionChunk to proto ActionChunk."""
        response = vla_inference_pb2.ActionChunk(
            inference_time_ms=chunk.inference_time_ms,
            model_version=chunk.model_version,
            confidence=chunk.confidence,
            sequence_number=chunk.sequence_number,
        )

        for action in chunk.actions:
            response.actions.append(vla_inference_pb2.Action(
                joint_commands=action.joint_commands,
                gripper_command=action.gripper_command,
                timestamp=action.timestamp,
            ))

        return response

    async def Predict(self, request, context):
        """
        Perform a single VLA inference.

        Args:
            request: Observation proto message
            context: gRPC context

        Returns:
            ActionChunk proto message
        """
        start_time = time.time()
        self.queue_depth += 1
        self.metrics.update_queue_depth(self.queue_depth)

        try:
            # Convert proto to domain object
            observation = self._observation_from_proto(request)

            logger.debug(
                f"Predict request: instruction='{observation.language_instruction}', "
                f"embodiment={observation.embodiment_tag}"
            )

            # Run inference with metrics tracking
            model_type = self._model.model_info.base_model
            with self.metrics.measure_latency(model_type, observation.embodiment_tag):
                action_chunk = self._model.predict(observation)

            inference_time = (time.time() - start_time) * 1000
            self.total_requests += 1
            self.latency_sum += inference_time

            # Update GPU metrics
            gpu_util, mem_util, mem_used, mem_total = self._get_gpu_stats()
            self.metrics.update_gpu_stats(gpu_util, mem_used, mem_total)

            # Convert to proto and return
            return self._action_chunk_to_proto(action_chunk, request.timestamp)

        except Exception as e:
            logger.error(f"Predict failed: {e}")
            self.metrics.record_request(
                self._model.model_info.base_model,
                "error"
            )
            raise

        finally:
            self.queue_depth -= 1
            self.metrics.update_queue_depth(self.queue_depth)

    async def StreamControl(
        self,
        request_iterator: AsyncIterator,
        context,
    ) -> AsyncIterator:
        """
        Bidirectional streaming for continuous control.

        Args:
            request_iterator: Stream of Observation messages
            context: gRPC context

        Yields:
            ActionChunk proto messages
        """
        sequence_number = 0
        model_type = self._model.model_info.base_model

        async for request in request_iterator:
            start_time = time.time()
            self.queue_depth += 1
            self.metrics.update_queue_depth(self.queue_depth)

            try:
                observation = self._observation_from_proto(request)

                # Run inference with metrics
                with self.metrics.measure_latency(model_type, observation.embodiment_tag):
                    action_chunk = self._model.predict(observation)

                inference_time = (time.time() - start_time) * 1000
                self.total_requests += 1
                self.latency_sum += inference_time
                sequence_number += 1

                # Update GPU metrics periodically
                if sequence_number % 10 == 0:
                    gpu_util, mem_util, mem_used, mem_total = self._get_gpu_stats()
                    self.metrics.update_gpu_stats(gpu_util, mem_used, mem_total)

                yield self._action_chunk_to_proto(action_chunk, request.timestamp)

            except Exception as e:
                logger.error(f"StreamControl iteration failed: {e}")
                self.metrics.record_request(model_type, "error")
                # Continue to next request instead of breaking

            finally:
                self.queue_depth -= 1
                self.metrics.update_queue_depth(self.queue_depth)

    async def GetModelInfo(self, request, context):
        """Return model metadata."""
        info = self._model.model_info
        return vla_inference_pb2.ModelInfo(
            model_name=info.model_name,
            model_version=info.model_version,
            action_dim=info.action_dim,
            chunk_size=info.chunk_size,
            supported_embodiments=info.supported_embodiments,
            image_width=info.image_width,
            image_height=info.image_height,
            base_model=info.base_model,
        )

    async def HealthCheck(self, request, context):
        """Return server health status."""
        gpu_util, memory_util, _, _ = self._get_gpu_stats()
        uptime = time.time() - self.start_time
        avg_latency = (
            self.latency_sum / self.total_requests
            if self.total_requests > 0
            else 0.0
        )

        return vla_inference_pb2.HealthStatus(
            ready=self._model.is_loaded,
            gpu_utilization=gpu_util,
            memory_utilization=memory_util,
            queue_depth=self.queue_depth,
            uptime_seconds=uptime,
            total_requests=self.total_requests,
            avg_latency_ms=avg_latency,
        )

    def reload_model(self, model_type: Optional[str] = None) -> None:
        """
        Hot-reload model (for model switching without restart).

        Args:
            model_type: New model type (uses config if None)
        """
        logger.info(f"Reloading model: {model_type or self.config.model_type}")

        # Unload current model
        if self._model.is_loaded:
            self._model.unload()

        # Update config if new type specified
        if model_type:
            self.config.model_type = model_type

        # Load new model
        self._model = self._create_and_load_model()

        # Update metrics
        info = self._model.model_info
        self.metrics.set_model_info(
            model_name=info.model_name,
            model_version=info.model_version,
            base_model=info.base_model,
            device=self._model.device,
        )

        logger.info("Model reloaded successfully")

    def shutdown(self) -> None:
        """Clean up resources."""
        logger.info("Shutting down servicer...")

        # Unload model
        if self._model and self._model.is_loaded:
            self._model.unload()

        # Shutdown GPU monitoring
        if HAS_PYNVML and self.gpu_handle is not None:
            try:
                pynvml.nvmlShutdown()
            except Exception:
                pass

        logger.info("Servicer shutdown complete")
